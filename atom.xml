<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>技术成长</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://caolinhua.me/"/>
  <updated>2018-04-15T07:48:59.000Z</updated>
  <id>http://caolinhua.me/</id>
  
  <author>
    <name>曹林华</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>秒杀架构设计</title>
    <link href="http://caolinhua.me/2018/03/11/%E7%A7%92%E6%9D%80%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    <id>http://caolinhua.me/2018/03/11/秒杀架构设计/</id>
    <published>2018-03-10T16:00:00.000Z</published>
    <updated>2018-04-15T07:48:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近在部门内部分享了原来做电商领域做秒杀活动的整体思路，大家对这个分享反馈还不错，所依我就整理出来，给大家参考参考<br><a id="more"></a></p><h1 id="业务介绍"><a href="#业务介绍" class="headerlink" title="业务介绍"></a>业务介绍</h1><p><img src="/img/jd.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">什么是秒杀？通俗一点讲就是网络商家为促销等目的组织的网上限时抢购活动</span><br></pre></td></tr></table></figure><p>比如说京东秒杀，就是一种定时定量秒杀，在规定的时间内，无论商品是否秒杀完毕，该场次的秒杀活动都会结束。这种秒杀，对时间不是特别严格，只要下手快点，秒中的概率还是比较大的。</p><p>还有淘宝出现过的一元抢购，一般都是限量 1 件商品，同时价格低到「令人发齿」，这种秒杀一般都在开始时间 1 秒内都已经抢光了，参与这个秒杀一般都是看运气的，不必太强求</p><h1 id="业务特点"><a href="#业务特点" class="headerlink" title="业务特点"></a>业务特点</h1><p><img src="/img/tedian.png" alt=""></p><h4 id="瞬时并发量大"><a href="#瞬时并发量大" class="headerlink" title="瞬时并发量大"></a>瞬时并发量大</h4><p>秒杀时会有大量用户在同一时间进行抢购，瞬时并发访问量突增 10 倍，甚至 100 倍以上。</p><h4 id="库存量少"><a href="#库存量少" class="headerlink" title="库存量少"></a>库存量少</h4><p>一般都是请求量比当前活动商品量多很多，只有少部分用户秒杀成功。</p><h4 id="业务简单"><a href="#业务简单" class="headerlink" title="业务简单"></a>业务简单</h4><p>流程比较简单，一般都是下订单减库存</p><h1 id="技术难点"><a href="#技术难点" class="headerlink" title="技术难点"></a>技术难点</h1><p><img src="/img/dif.png" alt=""></p><h4 id="现有业务的冲击"><a href="#现有业务的冲击" class="headerlink" title="现有业务的冲击"></a>现有业务的冲击</h4><p>一般秒杀是营销活动中的一种，如果和其他营销活动应用部署在同一服务器上，肯定会对现有业务形成冲击，极端情况下可能导致整个电商系统服务不好用</p><h4 id="直接下订单"><a href="#直接下订单" class="headerlink" title="直接下订单"></a>直接下订单</h4><p>通常情况下，下单页面是一个正常的 URL 地址，需要控制在秒杀开始前，不能下订单，只能浏览对应活动商品的信息。简单来说，需要 Disable 订单按钮</p><h4 id="页面流量突增"><a href="#页面流量突增" class="headerlink" title="页面流量突增"></a>页面流量突增</h4><p>秒杀活动时候，很多用户都会请求对应商品页面，会造成后台服务器的流量突增，同时对应的网络带宽增加，需要控制商品页面的流量不会对对应后台服务器、DB、Redis 等组件的压力</p><h1 id="架构设计思想"><a href="#架构设计思想" class="headerlink" title="架构设计思想"></a>架构设计思想</h1><p><img src="/img/xuef.png" alt=""></p><h4 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h4><p>由于活动库存量一般都是很少，对应的只有少部分用户才能秒杀成功。所以我们需要限制大部分用户流量，只准少量用户流量进入后端服务器</p><h4 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h4><p>秒杀开始的那一瞬间，会有大量用户冲击进来，所以在开始时候会有一个瞬间流量峰值。如何把瞬间的流量峰值变得更平缓写，也是设计该系统的重要因素。实现流量削峰填谷一般的采取措施，主要采用缓存和 MQ 中间件</p><h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><p>秒杀其实可以当做高并发系统来处理，在这个时候，需要业务上做兼容，将我们同步的业务，设计成异步处理的任务</p><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>秒杀系统的瓶颈主要体现在下订单、扣减库存流程中。这些流程中主要用到 OLTP 的数据库，类似 MySQL、SQLServer、Oracle。由于数据库底层采用 B+ 树的储存结构，对应我们随机写入与读取的效率，相对较低。如果我们把部分业务逻辑迁移到内存的缓存或者 Redis 中，会极大的提高并发效率</p><h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p><img src="/img/arch.png" alt=""></p><h2 id="客户端优化"><a href="#客户端优化" class="headerlink" title="客户端优化"></a>客户端优化</h2><p>客户端优化主要有两个问题</p><h4 id="秒杀页面"><a href="#秒杀页面" class="headerlink" title="秒杀页面"></a>秒杀页面</h4><p>秒杀活动开始前，其实就有很多用户访问该页面了。如果这个页面的一些资源，比如 CSS、JS、图片、商品详情等，都访问后端服务器，甚至 DB 的话，服务肯定会出现不可用的情况。所以一般我们会把这个页面整体进行静态化，并将页面静态化之后的页面分发到 CDN 边缘节点上，起到压力分散的作用</p><h4 id="防止提前下单"><a href="#防止提前下单" class="headerlink" title="防止提前下单"></a>防止提前下单</h4><p>防止提前下单主要是在上面静态化页面中加入一个 JS 文件引用，该 JS 文件包含活动是否开始的标记以及开始时的动态下单页面的 URL 参数。同时，这个 JS 文件是不会被 CDN 系统缓存的，会一直请求后端服务的，所以这个 JS 文件一定要很小。当活动快开始的时候（比如提前），通过后台接口修改这个 JS 文件使之生效</p><h2 id="API-接入层优化"><a href="#API-接入层优化" class="headerlink" title="API 接入层优化"></a>API 接入层优化</h2><p>客户端优化，对于不是搞计算机方面的用户还是可以防止住的。但是稍有一定网络基础的用户就起不到作用力，因此服务端也需要控制，不能完全信任客户端的操作。一般控制分为 2 大类</p><h4 id="限制用户维度访问频率"><a href="#限制用户维度访问频率" class="headerlink" title="限制用户维度访问频率"></a>限制用户维度访问频率</h4><p>针对同一个用户（ Userid 维度），做页面级别缓存，单元时间内的请求，统一走缓存，返回同一个页面</p><h4 id="限制商品维度访问频率"><a href="#限制商品维度访问频率" class="headerlink" title="限制商品维度访问频率"></a>限制商品维度访问频率</h4><p>大量同时间段查询同一个商品时，可以做页面级别缓存，不管下回是谁来访问，只要是这个页面就直接返回</p><h2 id="SOA-服务层优化"><a href="#SOA-服务层优化" class="headerlink" title="SOA 服务层优化"></a>SOA 服务层优化</h2><p>上面两层只能限制异常用户访问，如果秒杀活动运营的比较好，很多用户都参加了，就会造成系统压力过大甚至宕机，因此需要后端流量控制</p><p>对于后端系统的控制可以通过消息队列、异步处理、提高并发等方式解决。对于超过系统水位线的请求，直接采取 「Fail-Fast」原则，拒绝掉</p><h1 id="秒杀整体流程图"><a href="#秒杀整体流程图" class="headerlink" title="秒杀整体流程图"></a>秒杀整体流程图</h1><p><img src="/img/detail.png" alt=""></p><p>秒杀系统核心在于层层过滤，逐渐递减瞬时访问压力，减少最终对数据库的冲击。通过上面流程图就会发现压力最大的地方在哪里？ MQ 排队服务，只要 MQ 排队服务顶住，后面下订单与扣减库存的压力都是我们自己能控制的，根据数据库的压力，可以定制化创建订单消费者的数量，避免出现消费者梳理过大，导致数据库挂了。</p><p>库存服务专门为秒送的商品提高库存管理，实现提前锁定库存，避免超卖的现象。同时，通过超时处理任务发现用户已抢到商品，但未付款的订单，并在规定付款时间后，将恢复库存</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>核心思想：层层过滤</p><ul><li>尽量将请求拦截在上游，降低下游的压力</li><li>充分利用缓存与消息队列，提高请求处理速度以及削峰填谷的作用</li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li>秒杀业务架构优化之路<br>「<a href="http://www.infoq.com/cn/articles/flash-deal-architecture-optimization」" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/flash-deal-architecture-optimization」</a></li><li>互联网秒杀业务设计 「<a href="https://baijia.baidu.com/s?old_id=108134」" target="_blank" rel="noopener">https://baijia.baidu.com/s?old_id=108134」</a></li><li>高并发秒杀系统架构设计 「<a href="https://zhuanlan.zhihu.com/p/25368538」" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25368538」</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;最近在部门内部分享了原来做电商领域做秒杀活动的整体思路，大家对这个分享反馈还不错，所依我就整理出来，给大家参考参考&lt;br&gt;
    
    </summary>
    
    
      <category term="架构设计" scheme="http://caolinhua.me/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>区块链认知</title>
    <link href="http://caolinhua.me/2018/02/04/%E5%8C%BA%E5%9D%97%E9%93%BE%E8%AE%A4%E7%9F%A5/"/>
    <id>http://caolinhua.me/2018/02/04/区块链认知/</id>
    <published>2018-02-03T16:00:00.000Z</published>
    <updated>2018-04-15T07:50:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是区块链"><a href="#什么是区块链" class="headerlink" title="什么是区块链"></a>什么是区块链</h2><p>区块链是一种分布式数据库。</p><p>从本质上来说，区块链是利用分布式技术和共识算法重新构造的一种信任机制。可以把区块链简单理解为一个由所有参与者公共维护的交易账本，账本信息的公开使得所有参与者可以一起来校验交易和记账的正确性，使得账本具有防止恶意篡改的能力，成为所有参与者可以信任的载体。现在，区块链概念和技术被运用到更加广泛的互联网金融领域，人们觉得这可能成为未来一些行业内信息安全存储的主要技术手段。<br><a id="more"></a></p><h2 id="区块链和比特币的关系"><a href="#区块链和比特币的关系" class="headerlink" title="区块链和比特币的关系"></a>区块链和比特币的关系</h2><p>区块链技术是比特币的底层技术，在早期并没有太多人注意到比特币的底层技术。但是当比特币在没有任何中心化机构运营和管理的情况下，在多年里非常稳定的运行，并且没有出现过任何问题。所以很多人注意到，该底层技术技术也许有很大的机制，而且不仅仅可以在比特币中使用，也许可以在许多领域都能够应用这种技术。于是把比特币技术抽象提取出来，称之为区块链技术，或者分布式账本技术。</p><h2 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h2><p>区块链最重要的是解决了<strong>信用问题</strong>。</p><p>在过去，两个互不认识和信任的人要达成协作是难的，必须要依靠第三方。比如支付行为，在过去任何一种转账，必须要有银行或者支付宝这样的机构存在。但是通过区块链技术，比特币是人类第一次实现在没有任何中介机构参与的情况下，完成双方可以互信的转账行为。这是区块链的重大突破</p><h3 id="金融服务"><a href="#金融服务" class="headerlink" title="金融服务"></a>金融服务</h3><p>主要是降低交易成本，减少跨组织交易风险等。该领域的区块链应用将最快成熟起来，银行和金融交易机构将是主力推动者。</p><h3 id="征信和权属管理"><a href="#征信和权属管理" class="headerlink" title="征信和权属管理"></a>征信和权属管理</h3><p>这是大型社交平台和保险公司都梦寐以求的，目前还缺乏足够的数据来源、可靠的平台支持和有效的数据分析和管理。该领域创业的门槛极高，需要自上而下的推动。</p><h3 id="资源共享"><a href="#资源共享" class="headerlink" title="资源共享"></a>资源共享</h3><p>airbnb 为代表的公司将欢迎这类应用，极大降低管理成本。这个领域创业门槛低，主题集中，会受到投资热捧。</p><h3 id="投资管理"><a href="#投资管理" class="headerlink" title="投资管理"></a>投资管理</h3><p>无论公募还是私募基金，都可以应用区块链技术降低管理成本和管控风险。虽然有 DAO 这样的试水，谨慎认为该领域的需求还未成熟。</p><h3 id="物联网与供应链"><a href="#物联网与供应链" class="headerlink" title="物联网与供应链"></a>物联网与供应链</h3><p>物联网是很适合的一个领域，短期内会有大量应用出现，特别是租赁、物流等特定场景。但物联网自身的发展局限将导致短期内较难出现规模应用</p><h2 id="区块链技术"><a href="#区块链技术" class="headerlink" title="区块链技术"></a>区块链技术</h2><p>区块链技术作为比特币的核心技术，通俗的说就是一种分布式数据库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">* 随时提取   ——去中心化特性</span><br><span class="line">* 不可伪造   ——集体维护监督</span><br><span class="line">* 不可撤销   ——开源及匿名性</span><br><span class="line">* 可验证性   ——可分数据存储</span><br></pre></td></tr></table></figure><p>首先，因为整个网络没有中心统治者。系统依靠的是网络上多个参与者的公平约束，所以任意每几个节点的权利和义务都是均等的，而且每一个节点都会储存这个区块链上所有数据。即使该节点被损坏或遭受攻击，仍然不会对账簿造成任何威胁。</p><p>其次，得确保信息或合约无法伪造。账簿在某个人或某几人手上，造假的可能性就非常高，但每个人手里都有一本账簿，除非你说服了整个游戏里超过51%的人都更改某一笔账目，否则你的篡改都是无效的，这也是大众玩家集体维护和监督的优越性。</p><p>再而，区块链上的信息必须不可撤销，不能随意销毁。比特币的系统是开源的，整个系统都必须是公开透明的，因此某笔交易被全网广播以后，达到6个确认以上就成功记录在案了，且不可逆转不可撤销。所以你打出去的钱，即使后来发现地址打错了，你想要重新重新撤回来，是不可行的。</p><p>最后，区块链信息必须是可验证的。我可以经过信息提取来判定你的该笔记录是真实的还是伪造的。</p><h2 id="区块链目前问题"><a href="#区块链目前问题" class="headerlink" title="区块链目前问题"></a>区块链目前问题</h2><p>比如比特币在支付方面，当前比特币网络确认的交易是每秒最多7笔，而支付宝每秒则达到上万笔的交易确认。便捷性上来看，的确不如微信和支付宝，这个毋庸置疑，不过侧链和闪电网络正在攻克这些技术问题。</p><p>比如银行开户的成本是比较高昂的，但也无法避免，因为涉及到跨境支付，像目前对于不同的机构，做账对不上这些问题，其实都会cover到支付成本上去。区块链能提出什么好的解决方案么？</p><p>看似万能的区块链，实质上还处于一个瓶颈期。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>区块链之菜鸟入门 <a href="https://yq.aliyun.com/articles/60134" target="_blank" rel="noopener">https://yq.aliyun.com/articles/60134</a></li><li>区块链技术指南 <a href="https://yeasy.gitbooks.io/blockchain_guide/content/born/" target="_blank" rel="noopener">https://yeasy.gitbooks.io/blockchain_guide/content/born/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是区块链&quot;&gt;&lt;a href=&quot;#什么是区块链&quot; class=&quot;headerlink&quot; title=&quot;什么是区块链&quot;&gt;&lt;/a&gt;什么是区块链&lt;/h2&gt;&lt;p&gt;区块链是一种分布式数据库。&lt;/p&gt;
&lt;p&gt;从本质上来说，区块链是利用分布式技术和共识算法重新构造的一种信任机制。可以把区块链简单理解为一个由所有参与者公共维护的交易账本，账本信息的公开使得所有参与者可以一起来校验交易和记账的正确性，使得账本具有防止恶意篡改的能力，成为所有参与者可以信任的载体。现在，区块链概念和技术被运用到更加广泛的互联网金融领域，人们觉得这可能成为未来一些行业内信息安全存储的主要技术手段。&lt;br&gt;
    
    </summary>
    
    
      <category term="业界技术" scheme="http://caolinhua.me/tags/%E4%B8%9A%E7%95%8C%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>全链路跟踪设计与实践</title>
    <link href="http://caolinhua.me/2018/01/31/%E5%85%A8%E9%93%BE%E8%B7%AF%E8%B7%9F%E8%B8%AA%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    <id>http://caolinhua.me/2018/01/31/全链路跟踪设计与实践/</id>
    <published>2018-01-30T16:00:00.000Z</published>
    <updated>2018-04-15T07:51:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>随着沪江业务的高速发展，公司服务之间的调用关系愈加复杂，如何理清并跟踪它们之间的调用关系就显的比较关键。线上每一个请求会经过多个业务系统，并产生对各种缓存或者 DB 的访问，但是这些分散的数据对于问题排查，或者流程优化提供的帮助有限。在这样复杂的业务场景下，业务流会经过很多个微服务的处理和传递，我们难免会遇到这些问题:</p><a id="more"></a><ul><li>一次请求的流量从哪个服务而来？ 最终落到了哪个服务中去？</li><li>为什么这个请求这么慢? 到底哪个环节出了问题? </li><li>这个操作需要依赖哪些东西? 是数据库还是消息队列? Redis挂了，哪些业务受影响?  </li></ul><h1 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h1><ul><li>低消耗性：跟踪系统对业务系统的影响应该做到足够小。在一些高度优化过的服务，即使一点点损耗也容易察觉到，而且有可能迫使在线负责的部署团队不得不将跟踪系统关停</li><li>低侵入性：作为非业务组件，应当尽可能少侵入或者无侵入业务系统，对于使用方透明，减少开发人员的负担</li><li>时效性：从数据的收集产生，到数据计算处理，再到最终展现，都要求尽可能快</li><li>决策支持：这些数据是否能在决策支持层面发挥作用，特别是从 DevOps 的角度</li><li>数据可视化：做到不用看日志通过可视化进行筛选</li></ul><h1 id="实现功能"><a href="#实现功能" class="headerlink" title="实现功能"></a>实现功能</h1><ul><li>故障定位：调用链路跟踪，一次请求的逻辑轨迹可以完整清晰的展示出来。</li><li>性能分析：调用链的各个环节分别添加调用耗时，可以分析出系统的性能瓶颈，并针对性的优化。</li><li>数据分析：调用链是一条完整的业务日志，可以得到请求的行为路径，汇总分析应用在很多业务场景</li></ul><h1 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h1><p>对于上面那些问题，业内已经有了一些具体实践和解决方案。通过调用链的方式，把一次请求调用过程完整的串联起来，这样就实现了对请求链路的监控。</p><p>在业界，目前已知的分布式跟踪系统，比如「Twitter Zipkin 与淘宝鹰眼」，设计思想都是来自 Google Dapper 的论文 「Dapper, a Large-Scale Distributed Systems Tracing Infrastructure」</p><h3 id="典型分布式调用过程"><a href="#典型分布式调用过程" class="headerlink" title="典型分布式调用过程"></a>典型分布式调用过程</h3><p><img src="/img/img1.png" alt="image"></p><p>图1：这个路径由用户的X请求发起，穿过一个简单的服务系统。用字母标识的节点代表分布式系统中的不同处理过程。</p><p>分布式服务的跟踪系统需要记录在一次特定的请求后系统中完成的所有工作的信息。举个例子，图1展现的是一个和5台服务器相关的一个服务，包括：前端（A），两个中间层（B和C），以及两个后端（D和E）。当一个用户（这个用例的发起人）发起一个请求时，首先到达前端，然后发送两个 RPC 到服务器 B 和 C 。B 会马上做出反应，但是 C 需要和后端的 D 和 E 交互之后再返还给 A ，由 A 来响应最初的请求。对于这样一个请求，简单实用的全链路跟踪的实现，就是为服务器上每一次你发送和接收动作来收集与跟踪</p><h3 id="调用链路关系图"><a href="#调用链路关系图" class="headerlink" title="调用链路关系图"></a>调用链路关系图</h3><p><img src="/img/img3.png" alt="image"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cs - CLIENT_SEND，客户端发起请求</span><br><span class="line">sr - SERVER_RECIEVE，服务端收到请求</span><br><span class="line">ss - SERVER_SEND，服务端处理完成，发送结果给客户端</span><br><span class="line">cr - CLIENT_RECIEVE，客户端收到响应</span><br></pre></td></tr></table></figure><h1 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h1><table><thead><tr><th>公司</th><th>选项</th><th>是否开源</th><th>优缺点</th></tr></thead><tbody><tr><td>淘宝</td><td>EagleEye</td><td>否</td><td>主要基于内部 HSF 实现，HSF 没有开源，故鹰眼也没有开源</td></tr><tr><td>Twitter</td><td>Zipkin</td><td>是</td><td>基于 Http 实现，支持语言较多，比较适合我们公司业务</td></tr><tr><td>点评</td><td>CAT</td><td>是</td><td>自定义改造难度大，代码比较复杂，侵入代码，需要埋点</td></tr><tr><td>京东</td><td>Hydra</td><td>是</td><td>主要基于 Dubbo 实现，不适合公司 Http 请求为主的场景</td></tr></tbody></table><p>综上，考虑到公司目前以 Http 请求为主的场景，最终决定采用参考 Zipkin 的实现思路，同时以 OpenTracing 标准来兼容多语言客户端</p><h1 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h1><h2 id="整体架构图及说明"><a href="#整体架构图及说明" class="headerlink" title="整体架构图及说明"></a>整体架构图及说明</h2><p><img src="/img/img4.png" alt="image"></p><p>一般全链路跟踪系统主要有四个部分：数据埋点、数据传输、数据存储、查询界面</p><h2 id="数据埋点"><a href="#数据埋点" class="headerlink" title="数据埋点"></a>数据埋点</h2><ul><li>通过集成 SDK 到沪江统一开发框架中，进行低侵入性的数据收集</li><li>采用 AOP 切面方式，将收集的数据存储在本地线程变量 ThreadLocal 中，对应用透明</li><li>数据记录 TraceId、事件应用、接口、开始时间、耗时</li><li>数据采用异步线程队列的方式发送到 Kafka 队列中，减少对业务的影响</li></ul><p>目前支持的中间件有：</p><ul><li>Http 中间件</li><li>Mysql 中间件</li><li>RabbitMQ 中间件</li></ul><h2 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h2><p>我们在 SDK 与后端服务之间加了一层 Kafka ，这样做既可以实现工程解耦，又可以实现数据的延迟消费，起到削峰填谷的作用。我们不希望因为瞬时 QPS 过高而导致数据丢失，当然为此也付出了一些实效性上的代价。</p><h4 id="Kafka-Manager-展示"><a href="#Kafka-Manager-展示" class="headerlink" title="Kafka Manager 展示"></a>Kafka Manager 展示</h4><p><img src="/img/kafka.png" alt="image"></p><h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>数据存储采用 ElasticSearch ，主要存储 Span 与 Annotation 相关的数据，考虑到数据量的规模，先期只保存最近 1 个月的数据。</p><h4 id="ELasticSearch-Head-数据"><a href="#ELasticSearch-Head-数据" class="headerlink" title="ELasticSearch Head 数据"></a>ELasticSearch Head 数据</h4><p><img src="/img/es.png" alt="image"></p><h2 id="查询界面"><a href="#查询界面" class="headerlink" title="查询界面"></a>查询界面</h2><p>通过可视化 Web 界面来查询分布式调用链路，同时还提供根据项目维度分析依赖聚合</p><h3 id="查询页面"><a href="#查询页面" class="headerlink" title="查询页面"></a>查询页面</h3><p><img src="/img/home.png" alt="image"></p><h3 id="Trace-树"><a href="#Trace-树" class="headerlink" title="Trace 树"></a>Trace 树</h3><p><img src="/img/trace.png" alt="image"></p><h3 id="依赖分析"><a href="#依赖分析" class="headerlink" title="依赖分析"></a>依赖分析</h3><p><img src="/img/dependency.png" alt="image"></p><h1 id="遇到的一些坑"><a href="#遇到的一些坑" class="headerlink" title="遇到的一些坑"></a>遇到的一些坑</h1><h3 id="Web-页面加载超时"><a href="#Web-页面加载超时" class="headerlink" title="Web 页面加载超时"></a>Web 页面加载超时</h3><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>使用 Zipkin 官网 UI 的时候，会偶发性的出现业务加载超时。</p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>原因是 Zipkin 加载页面的时候会一次性加载该项目里面所有的 Span ，当项目使用 Restful 形式的 API 时，就会产生几百万的 Span。最后，我们重写 UI 页面采用懒加载的方式，默认展示最近 10 条 Span，同时支持输入字符来动态查询 Span 的功能。</p><h3 id="Span-堆积过多"><a href="#Span-堆积过多" class="headerlink" title="Span 堆积过多"></a>Span 堆积过多</h3><p><img src="/img/dependency.png" alt="image"></p><h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><p>当使用页面查询 Trace 的时候，发现某个链路堆积到上千条 Span </p><h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p>排查下来，业务方使用 HttpClient 中间件发送 Http 请求超时的时候，SDK 并未拦截超时对应的异常，导致事件一直在存储在线程对应的 ThreadLocal 中</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>全链路跟踪系统关键点：调用链。</p><p>每次请求都生成全局唯一的 TraceID，通过该 ID 将不同的系统串联起来。实现调用链跟踪，路径分析，帮助业务人员快速定位性能瓶颈，排查故障原因。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li>Google Dapper <a href="http://bigbully.github.io/Dapper-translation/" target="_blank" rel="noopener">http://bigbully.github.io/Dapper-translation/</a></li><li>Twitter <a href="http://zipkin.io/" target="_blank" rel="noopener">Zipkin</a></li><li>窝窝网 Tracing 文章 <a href="http://www.cnblogs.com/zhengyun_ustc/p/55solution2.html" target="_blank" rel="noopener">http://www.cnblogs.com/zhengyun_ustc/p/55solution2.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;随着沪江业务的高速发展，公司服务之间的调用关系愈加复杂，如何理清并跟踪它们之间的调用关系就显的比较关键。线上每一个请求会经过多个业务系统，并产生对各种缓存或者 DB 的访问，但是这些分散的数据对于问题排查，或者流程优化提供的帮助有限。在这样复杂的业务场景下，业务流会经过很多个微服务的处理和传递，我们难免会遇到这些问题:&lt;/p&gt;
    
    </summary>
    
    
      <category term="架构设计" scheme="http://caolinhua.me/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>如何确定线程池大小</title>
    <link href="http://caolinhua.me/2017/12/30/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%A4%A7%E5%B0%8F/"/>
    <id>http://caolinhua.me/2017/12/30/线程池大小/</id>
    <published>2017-12-29T16:00:00.000Z</published>
    <updated>2018-04-15T07:51:47.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在我们日常业务开发过程中，或多或少都会用到并发的功能。如果用到并发的话，那肯定就要碰到下面这个问题</p><blockquote><p>并发线程池到底设置多大呢？<br><a id="more"></a><br>通常有点年纪的程序员或许都听说这样一个说法 （其中 N 代表 CPU 的个数）</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. CPU 密集型应用，线程池大小设置为 N + 1</span><br><span class="line">2. IO 密集型应用，线程池大小设置为 2N</span><br></pre></td></tr></table></figure><p>这个说法到底是不是正确的呢？</p><p>其实这是极不正确的。那为什么呢？</p><ul><li>首先我们从反面来看，假设这个说法是成立的，那我们在一台服务器上部署多少个服务都无所谓了。因为线程池的大小只能服务器的核数有关，所以这个说法是不正确的。那具体应该怎么设置大小呢？</li><li>假设这个应用是两者混合型的，其中任务即有 CPU 密集，也有 IO 密集型的，那么我们改怎么设置呢？是不是只能抛硬盘来决定呢？</li></ul><p>那么我们到底该怎么设置线程池大小呢？有没有一些具体实践方法来指导大家落地呢？让我们来深入地了解一下。</p><h2 id="Little’s-Law（利特尔法则）"><a href="#Little’s-Law（利特尔法则）" class="headerlink" title="Little’s Law（利特尔法则）"></a>Little’s Law（利特尔法则）</h2><p><img src="https://res.infoq.com/articles/Java-Thread-Pool-Performance-Tuning/zh/resources/0930001.jpg" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个系统请求数等于请求的到达率与平均每个单独请求花费的时间之乘积</span><br></pre></td></tr></table></figure><p>假设服务器单核的，对应业务需要保证请求量（QPS）：10 ，真正处理一个请求需要 1 秒，那么服务器每个时刻都有 10 个请求在处理，即需要 10 个线程</p><p><img src="https://res.infoq.com/articles/Java-Thread-Pool-Performance-Tuning/zh/resources/0930000.jpg" alt=""></p><p>同样，我们可以使用利特尔法则（Little’s law）来判定线程池大小。我们只需计算请求到达率和请求处理的平均时间。然后，将上述值放到利特尔法则（Little’s law）就可以算出系统平均请求数。估算公式如下</p><blockquote><p><strong>线程池大小 = （（线程 IO time + 线程 CPU time ）/线程 CPU time ）* CPU数目</strong></p></blockquote><h2 id="具体实践"><a href="#具体实践" class="headerlink" title="具体实践"></a>具体实践</h2><p>通过公式，我们了解到需要 3 个具体数值</p><ol><li>一个请求所消耗的时间 (线程 IO time + 线程 CPU time)</li><li>该请求计算时间 （线程 CPU time）</li><li>CPU 数目</li></ol><h3 id="请求消耗时间"><a href="#请求消耗时间" class="headerlink" title="请求消耗时间"></a>请求消耗时间</h3><p>Web 服务容器中，可以通过 Filter 来拦截获取该请求前后消耗的时间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public class MoniterFilter implements Filter &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(MoniterFilter.class);</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException,</span><br><span class="line">            ServletException &#123;</span><br><span class="line">        long start = System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">        HttpServletRequest httpRequest = (HttpServletRequest) request;</span><br><span class="line">        HttpServletResponse httpResponse = (HttpServletResponse) response;</span><br><span class="line">        String uri = httpRequest.getRequestURI();</span><br><span class="line">        String params = getQueryString(httpRequest);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            chain.doFilter(httpRequest, httpResponse);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            long cost = System.currentTimeMillis() - start;</span><br><span class="line">            logger.info(&quot;access url [&#123;&#125;&#123;&#125;], cost time [&#123;&#125;] ms )&quot;, uri, params, cost);</span><br><span class="line">        &#125;</span><br><span class="line">  </span><br><span class="line">    private String getQueryString(HttpServletRequest req) &#123;</span><br><span class="line">        StringBuilder buffer = new StringBuilder(&quot;?&quot;);</span><br><span class="line">        Enumeration&lt;String&gt; emParams = req.getParameterNames();</span><br><span class="line">        try &#123;</span><br><span class="line">            while (emParams.hasMoreElements()) &#123;</span><br><span class="line">                String sParam = emParams.nextElement();</span><br><span class="line">                String sValues = req.getParameter(sParam);</span><br><span class="line">                buffer.append(sParam).append(&quot;=&quot;).append(sValues).append(&quot;&amp;&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return buffer.substring(0, buffer.length() - 1);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            logger.error(&quot;get post arguments error&quot;, buffer.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        return &quot;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CPU-计算时间"><a href="#CPU-计算时间" class="headerlink" title="CPU 计算时间"></a>CPU 计算时间</h3><blockquote><p>CPU 计算时间 = 请求总耗时 - CPU IO time</p></blockquote><p>假设该请求有一个查询 DB 的操作，只要知道这个查询 DB 的耗时（CPU IO time），计算的时间不就出来了嘛，我们看一下怎么才能简洁，明了的记录 DB 查询的耗时。通过（JDK 动态代理/ CGLIB）的方式添加 AOP 切面，来获取线程 IO 耗时。代码如下，请参考</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">public class DaoInterceptor implements MethodInterceptor &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(DaoInterceptor.class);</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Object invoke(MethodInvocation invocation) throws Throwable &#123;</span><br><span class="line">        StopWatch watch = new StopWatch();</span><br><span class="line">        watch.start();</span><br><span class="line">        Object result = null;</span><br><span class="line">        Throwable t = null;</span><br><span class="line">        try &#123;</span><br><span class="line">            result = invocation.proceed();</span><br><span class="line">        &#125; catch (Throwable e) &#123;</span><br><span class="line">            t = e == null ? null : e.getCause();</span><br><span class="line">            throw e;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            watch.stop();</span><br><span class="line">            logger.info(&quot;(&#123;&#125;ms)&quot;, watch.getTotalTimeMillis());</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">### CPU 数目</span><br><span class="line">逻辑 CPU 个数 ，设置线程池大小的时候参考的 CPU 个数</span><br></pre></td></tr></table></figure><p>cat /proc/cpuinfo| grep “processor”| wc -l<br><code>`</code></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>合适的配置线程池大小其实很不容易，但是通过上述的公式和具体代码，我们就能快速、落地的算出这个线程池该设置的多大。不过最后的最后，我们还是需要通过压力测试来进行微调，只有经过压测测试的检验，我们才能最终保证的配置大小是准确的。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://en.wikipedia.org/wiki/Little&#39;s_law" target="_blank" rel="noopener">Little’s law</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在我们日常业务开发过程中，或多或少都会用到并发的功能。如果用到并发的话，那肯定就要碰到下面这个问题&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;并发线程池到底设置多大呢？&lt;br&gt;
    
    </summary>
    
    
      <category term="软件研发" scheme="http://caolinhua.me/tags/%E8%BD%AF%E4%BB%B6%E7%A0%94%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>系统思考</title>
    <link href="http://caolinhua.me/2017/12/24/%E7%B3%BB%E7%BB%9F%E6%80%9D%E8%80%83/"/>
    <id>http://caolinhua.me/2017/12/24/系统思考/</id>
    <published>2017-12-23T16:00:00.000Z</published>
    <updated>2018-04-15T07:51:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近发现一本关于提高系统思维能力的书，是一本你读起来很容易接受，逻辑很清楚的书。</p><a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一般在我们工作或者生活的过程中都会碰到下面三中情况</p><ul><li>遇到事情突然想不清楚</li><li>表达时说不清楚</li><li>学习的时候学的慢</li></ul><p>以上的场景可能不是所有人都遇到过，但这个不是最关键的。关键的是你能通过这三个场景意识到自己的系统思维能力不足。</p><p>在「大数据」、「互联网」的社会中，优秀的思维能力是现代高素质人材必备能力。</p><p>那么我们该如何才能真正的提升思维能力呢？我们先看一下到底什么是思维能力</p><blockquote><p>系统思维是通过用框架来系统思考与表达的思维方式</p></blockquote><h2 id="系统分析与解决问题"><a href="#系统分析与解决问题" class="headerlink" title="系统分析与解决问题"></a>系统分析与解决问题</h2><p>通过具体案例，我们大致了解到运用具体框架分析与解决问题的主要步骤。下面我们先从「确定问题」开始</p><p><img src="http://images2017.cnblogs.com/blog/524680/201712/524680-20171224201357740-2069811427.png" alt=""></p><h3 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h3><p>什么是问题？ 一言以蔽之，问题就是源于现实与目标之间的差距。因此，问题产生的原因可以是</p><ul><li>不清楚目标是什么</li><li>不知道现实是什么</li><li>不知道差距产生的原因</li></ul><p>总之，问题产生的根源非常多，要想把所有问题产生的原因都列全的话，那绝对是不可能的。</p><p>但是我们却可以将生活、工作中遇到的常见问题分成三类</p><ol><li>未能准备描述问题 </li><li>没有梳理清楚问题的结构</li><li>被问题的表象蒙蔽</li></ol><h4 id="准备描述问题"><a href="#准备描述问题" class="headerlink" title="准备描述问题"></a>准备描述问题</h4><p>需要将非量化、模糊化、有歧义的问题转换可量化、可举例、清晰化的问题</p><h4 id="问题的构成要素"><a href="#问题的构成要素" class="headerlink" title="问题的构成要素"></a>问题的构成要素</h4><p> 5W2H分析法，易于使用、理解，对于决策和执行性的活动有帮助，也有助于弥补考虑问题的漏洞。<br> 具体场景 ： 如果项目经理让你出差到上海的问题。可以运用 「5W2H」的框架确定所有要素</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* Why 为什么要你去</span><br><span class="line">* What 项目情况以及要你过去做什么</span><br><span class="line">* When 具体什么时候开始，什么时候结束</span><br><span class="line">* Who 都有谁一起去看</span><br><span class="line">* How 怎么过去？坐飞机还是火车</span><br><span class="line">* How Much 有多少预算可以用</span><br></pre></td></tr></table></figure><h4 id="探寻问题本质"><a href="#探寻问题本质" class="headerlink" title="探寻问题本质"></a>探寻问题本质</h4><p>在日常工作、生活中，很多时候大家提出的问题都是经过初步加工后的解决方案，而非真正的问题。将问题的初步解决方案与问题本身混为一谈是最容易犯的错误，也是浪费大量时间与精力。你需要找到真正的问题，而不是惯性的将初步解决方案当做问题本身来应对。</p><h2 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h2><h3 id="自下而上"><a href="#自下而上" class="headerlink" title="自下而上"></a>自下而上</h3><p>自下而上提炼框架是一个先发散再收敛的思考过程，目的是提炼出一个结构完整、逻辑清晰的框架，以帮助下一步系统的解决问题。具体操作分为四步</p><ul><li>罗列要点：是一个发散思考的步骤，输出结果一张半成品的思维导图</li><li>连线归类：对上面的结果进行收敛归类的步骤，输出结果是一张成形的思维导图。该步骤关键是掌握归纳推理的三个逻辑顺序（时间顺序、结构顺序、重要性顺序），演绎的逻辑顺序</li><li>形成框架：将思维导图转换为问题解决框架的步骤，输出结果为逻辑树</li><li>检查框架：检查框架是否符合 MECE 的步骤</li></ul><h3 id="自上而下"><a href="#自上而下" class="headerlink" title="自上而下"></a>自上而下</h3><h4 id="选择框架"><a href="#选择框架" class="headerlink" title="选择框架"></a>选择框架</h4><p>快速选择一个合适的框架，是自上而下选用框架的最重要的一步。 </p><blockquote><p>What -&gt; Why -&gt; How<br>大家遇到遇到常见问题解决三步曲 「问题 - 原因 - 解决方案」 也就是 「What - Why - How」的思考框架：先分析问题现状，再分析导致问题产生的原因，最后再针对原因提出对策。</p></blockquote><p>自下而上与自上而下框架各有优劣，在时间思考过程中两者很难严格区分，需要综合运用</p><h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>前面我们了解了发现问题、分析问题的方法，并梳理出问题解决的措施清单。接下来到解决问题的环节： 如何高效执行解决措施、如何检查执行效果并调整</p><h3 id="高效执行"><a href="#高效执行" class="headerlink" title="高效执行"></a>高效执行</h3><p> 高效执行的关键在于有一个合理的机会，以及掌握执行机计划的有效工作方法</p><h4 id="制订计划"><a href="#制订计划" class="headerlink" title="制订计划"></a>制订计划</h4><p>在分析问题阶段强调框架先行，同意在解决问题阶段也是框架先行。那么我们搜星要找出一个编制机会的框架</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Why 为什么</span><br><span class="line">What 做什么</span><br><span class="line">When 什么时候开始，什么时间结束</span><br><span class="line">Who 谁来做</span><br><span class="line">Where 在哪里做</span><br><span class="line">How 具体怎么做</span><br><span class="line">How Much 需要多少资源</span><br></pre></td></tr></table></figure><h4 id="检查调整"><a href="#检查调整" class="headerlink" title="检查调整"></a>检查调整</h4><p>根据计划时间点，引入监控机制，对关键时间点进行关键节点并监控，一旦出现偏差，则及时跟进，并提出相应的改进措施，然后更新机会，最终形成一个 PDCA 循环<br><img src="http://images2017.cnblogs.com/blog/524680/201712/524680-20171224201344162-1744177577.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近发现一本关于提高系统思维能力的书，是一本你读起来很容易接受，逻辑很清楚的书。&lt;/p&gt;
    
    </summary>
    
    
      <category term="思考思维" scheme="http://caolinhua.me/tags/%E6%80%9D%E8%80%83%E6%80%9D%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>用户中心设计</title>
    <link href="http://caolinhua.me/2017/12/17/%E7%94%A8%E6%88%B7%E4%B8%AD%E5%BF%83%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    <id>http://caolinhua.me/2017/12/17/用户中心系统设计/</id>
    <published>2017-12-16T16:00:00.000Z</published>
    <updated>2018-04-15T07:52:08.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一般来说大型互联网公司会把授权和用户信息的逻辑放到一个应用中，而这个应用我们统一称为用户中心。</p><p>用户中心不关心具体的业务逻辑，只处理用户信息相关的管理及授权登录。当第三方应用需要登录的时候，会把用户的登录请求转发到用户中心处理，处理完毕后，返回给第三方应用，第三方应用根据对应的凭证登录到系统内部。<br><a id="more"></a></p><p>主要功能如下</p><ul><li>用户登录与注册</li><li>基本信息查询与修改</li></ul><p>从功能来看，整个用户中心还是很简单单，不过其中的逻辑还挺复杂的，比如注册功能，就要分为手机注册与邮箱注册，手机要发送手机验证码，邮箱需要发送验证邮件，点击邮箱里面的链接跳转并进行后续注册流程，上面每步都需要业务上重新发送机制。</p><h2 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h2><h3 id="用户登录"><a href="#用户登录" class="headerlink" title="用户登录"></a>用户登录</h3><p>在互联网用户中心体系中，一般会支持手机、邮箱、帐号、三方登录。其中三方登录一般会接入 QQ、微信、微博这三种方式。</p><h4 id="密码登录"><a href="#密码登录" class="headerlink" title="密码登录"></a>密码登录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 用户在浏览器端填写 username + password ，然后提交到服务端</span><br><span class="line">2. 服务端拿到用户提交的 username + password 验证。</span><br><span class="line">3. 验证成功后，服务器返回请求，同时将 cookie 写到对应域</span><br></pre></td></tr></table></figure><p>上述流程中，大家肯定会考虑到密码的安全性，我们到底该怎么做才能防止密码被泄露？对称加密还是非对称加密? 如果是对称加密，客户端被黑客反编译，就能拿到密钥，那么所有用户的密码就会存在非常大的泄露风险？如果是非对称加密，私钥要放在哪里才能保证安全？</p><p>通用简单的解决方案: Https + MD5 + 随机盐</p><p>Https 我就不用在述说了，基本上 Chrome、Firfox 都对不是 Https 的站点进行安全提醒，所以 Https 该上的还是尽快上吧</p><p>那如果公司很穷，买不起 Https 证书咋办呢？那么只能在前端页面上做点文章。<br>由于前端代码暴露在浏览器上，我们只能采用不可逆的密码或者摘要算法，类是与 MD5 / Hash 算法 。如果高级的话，就采用随机 Salt 来提高攻击成本，针对不同用户，加入不同的 Salt，而不是固定盐的方式。使用这种方式的前提「目前对安全的要求不高」</p><p>那我们该如何验证密码？客户端端提交 MD5(password）密码。服务端通过 MD5 (Salt + MD5(passowrd))的逻辑来计算最终密码，同时 Salt 只会出现在服务端，且每个用户采用不同 Salt 的方式来生成。这一系列过程中，都没有接触到原始的用户密码，如果出现用户的密码被劫持的话，只会发生在用户在提交密码前截获，这个也就是为什么需要密码控件？</p><h4 id="三方登录"><a href="#三方登录" class="headerlink" title="三方登录"></a>三方登录</h4><p>当用户以某种登录方式成功登录之后，我们能可以获取到对应 User 表中的用户基础信息，而登录操作只是为了认证用户这个过程，无论用本地密码验证还是第三方登录，以上过程本质上都是认证的形式。</p><p>所以用户的信息与登录的授权其实是独立开来的，即 uid 与 登录方式是一对多的关系。比如： 用户 A 使用「微信」登录，服务端认证身份后 uid = abc。而下一次用户 A 使用「微博」登录，同样服务端认证出来 uid = abc。<br>用户信息表（user_base）只存储用户 Profile 相关信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> id | name | city</span><br><span class="line">----+------+-----------------</span><br><span class="line"> A1 | Tom  | 上海</span><br><span class="line"> A2 | Jack |  背景</span><br></pre></td></tr></table></figure><p>而本地密码验证可以当做一种授权方式，可以称为 local_auth 表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> id | user_id | password</span><br><span class="line">----+---------+----------</span><br><span class="line"> 1 | A1      | qazwsx</span><br><span class="line"> 2 | A2      | edcrfv</span><br></pre></td></tr></table></figure><p>而通过微博登录就可以视作为另外一种登录方式，称为 weibo_auth 表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> id | user_id | weibo_id | weibo_access_token | weibo_expires</span><br><span class="line">----+---------+----------+--------------------+---------------</span><br><span class="line"> 1 | A1      | W-qaz | xxxxxxxxxx         | 604800</span><br><span class="line"> 2 | A2      | W-wsx | xxxxxxxxxx         | 604800</span><br></pre></td></tr></table></figure><p>最后，如果还要增加一种登录方式的话，可以直接添加一直 xx_auth 表来存储用户认证信息，大大提高了我们授权方式的灵活性</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;一般来说大型互联网公司会把授权和用户信息的逻辑放到一个应用中，而这个应用我们统一称为用户中心。&lt;/p&gt;
&lt;p&gt;用户中心不关心具体的业务逻辑，只处理用户信息相关的管理及授权登录。当第三方应用需要登录的时候，会把用户的登录请求转发到用户中心处理，处理完毕后，返回给第三方应用，第三方应用根据对应的凭证登录到系统内部。&lt;br&gt;
    
    </summary>
    
    
      <category term="架构设计" scheme="http://caolinhua.me/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>技术演讲需要准备什么</title>
    <link href="http://caolinhua.me/2017/12/03/%E6%8A%80%E6%9C%AF%E6%BC%94%E8%AE%B2%E9%9C%80%E8%A6%81%E5%87%86%E5%A4%87%E4%BB%80%E4%B9%88/"/>
    <id>http://caolinhua.me/2017/12/03/技术演讲需要准备什么/</id>
    <published>2017-12-02T16:00:00.000Z</published>
    <updated>2018-04-15T07:48:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近参加了 SA Summit 2017 的技术大会分享，在这边总结下并分享一下自己是如何准备的。请老司机们多提点建议。<br><a id="more"></a></p><h2 id="一、了解观众的诉求"><a href="#一、了解观众的诉求" class="headerlink" title="一、了解观众的诉求"></a>一、了解观众的诉求</h2><p>了解需求永远是做任何事的第一步，脱离了观众的诉求都是偏题的。</p><p>首先需要知道这次技术分享的主题大方向是什么？是分布式架构、前端架构，还是运维架构。<br>同时需要考虑到你的听众是谁？是 5 年以上的架构师，还是 3 年左右的工程师，不一样的听众背景决定了分享的侧重点，只有考虑到了听众的技术背景，才能有针对性的思考哪些内容可以详细解释，哪些可以一笔带过。</p><h2 id="二、好的开始是成功的一半"><a href="#二、好的开始是成功的一半" class="headerlink" title="二、好的开始是成功的一半"></a>二、好的开始是成功的一半</h2><p>开头的几分钟主要是自我介绍、演讲大纲介绍。一般自我介绍的时候，主要告诉大家</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">我是谁？</span><br><span class="line">来自什么公司？</span><br><span class="line">目前是什么职位及相关的从业经历</span><br></pre></td></tr></table></figure><p>表达好自我介绍后，一定要告诉听众此次演讲对大家有什么好处。听完之后大家会收获什么知识，能够解决什么问题。</p><p>如果安全的度过开始的三分钟，对应的紧张的情绪会极大的缓解。此时可以全神贯注的进行后面分享的内容。</p><p>举个这个分享用过的例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">大家好，我是来自 XX 公司的架构师 XXX </span><br><span class="line">我原先在百度负责过 XX 系统，具有高并发、大流量的架构经验</span><br><span class="line">接下来我会带着大家介绍 XX 公司 XX 系统的具体实践</span><br><span class="line">通过本次分享，希望大家能学到通过使用 XX 能很好的解决公司 XX 问题</span><br></pre></td></tr></table></figure><p>同时提点小的建议</p><ul><li>提前来到现场 ：与前排的听众进行简单的沟通，熟悉一下，可以减少很大的压力</li><li>分享前进行小调查 : 在坐的各位原来使用过这个 XX 技术吗？通过举手来进行互动与反馈</li></ul><h2 id="三、内容思路"><a href="#三、内容思路" class="headerlink" title="三、内容思路"></a>三、内容思路</h2><p>暖场后，最重要的就是演讲的思路，一般技术型演讲通过总分总的结构比较合适</p><blockquote><p>问题背景 - 方案对比 - 方案落地 - 方案收益 - 总结</p></blockquote><ul><li>问题背景 ： 了解下问题产生的原因是什么？为什么要解决这个问题？</li><li>方案对比 ： 带着听众进行方案的思路以及优劣对比，最好有真实的数据展示</li><li>方案落地 ： 让听众了解具体方案落地，有哪些需要注意的坑，通过什么方法能解决这些问题</li><li>方案收益 ： 落地之后，需要拿出真实的数据，体现出实施该方案的好处</li><li>总结 ： 总结下实施过程的经验，以及后续的一些规划</li></ul><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>最后演讲结束的时候，一定要进行总结，反复强调需要分享给听众的观点，最好不超过 3 个。这个部分不在多，而在于精，只要听众了解一个哪怕一个观点也是有收货的</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近参加了 SA Summit 2017 的技术大会分享，在这边总结下并分享一下自己是如何准备的。请老司机们多提点建议。&lt;br&gt;
    
    </summary>
    
    
      <category term="演讲分享" scheme="http://caolinhua.me/tags/%E6%BC%94%E8%AE%B2%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>容量规划</title>
    <link href="http://caolinhua.me/2017/12/03/%E5%AE%B9%E9%87%8F%E8%A7%84%E5%88%92/"/>
    <id>http://caolinhua.me/2017/12/03/容量规划/</id>
    <published>2017-12-02T16:00:00.000Z</published>
    <updated>2018-04-15T07:51:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>当我们在做大促，类似于双十一的活动时候，老板就会跑过来问我们这些问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.线上服务能承受多大的访问量</span><br><span class="line">2.单台服务器能承受多大的访问量</span><br><span class="line">3.需要加机器吗？需要加多少台机器</span><br></pre></td></tr></table></figure><a id="more"></a><p>这个时候，就体现出容量规划的重要性了。那到底什么是容量规划呢？</p><blockquote><p>容量规划是以当前的性能作为基线，来决定你需要什么及什么时候需要</p></blockquote><h2 id="容量-VS-性能"><a href="#容量-VS-性能" class="headerlink" title="容量 VS 性能"></a>容量 VS 性能</h2><ul><li>性能：决定一辆车能装什么东西</li><li>容量：决定需要多少量车</li></ul><p>容量规划可以分解为下面 4 个步骤</p><ul><li>明确目标</li><li>收集指标</li><li>趋势预测</li><li>容量部署</li></ul><h2 id="明确目标"><a href="#明确目标" class="headerlink" title="明确目标"></a>明确目标</h2><blockquote><p>在没有明确网站需求之前，不应该开始容量规划。</p></blockquote><p>一般每个服务都有对外承诺的服务质量，那么我们就需要根据这个目标来做容量规划及硬件方面的投入。</p><p>比如 A 网站能承受 3000 QPS，响应时间小于 200 ms。</p><p><strong>SLA (服务等级协议)</strong></p><p><img src="http://images2017.cnblogs.com/blog/524680/201712/524680-20171206222454253-53627087.jpg" alt=""></p><h2 id="收集指标"><a href="#收集指标" class="headerlink" title="收集指标"></a>收集指标</h2><blockquote><p>不知道当前服务能承受的容量范围的话，不建议进行容量方面的规划。</p></blockquote><p>我们需要通过测试来了解当前服务的数据指标。没有测试出你的服务上限的话，规划出来也是没有效果的。</p><p>测试主要分为下面 2 个步骤</p><ul><li>测试服务器的主要功能 ：业务维度 QPS、TPS</li><li>测试服务器硬件资源 ： CPU、内存、硬盘、网络</li></ul><h2 id="趋势预测"><a href="#趋势预测" class="headerlink" title="趋势预测"></a>趋势预测</h2><blockquote><p>预测容量是一个持续的过程，需要靠数学与直觉来进行精确的预测。</p></blockquote><p>整体过程如下</p><ul><li>首先确定资源度量指标 ：比如内存消耗、硬盘消耗、CPU 消耗</li><li>其实对拥有的资源确定约束访问 : 比如 总内存大小、总硬盘大小等</li><li>最后根据监控趋势图（ Zabbix 、Metrics）算出具体容量超出时间点 ： 比如内存何时会耗尽</li></ul><h2 id="容量部署"><a href="#容量部署" class="headerlink" title="容量部署"></a>容量部署</h2><p>一旦确定未来需要多少容量才能满足业务需求，就可以着手新的设备，并进行部署。</p><p>通过自动化部署工具（ Ansible、 Salt ） 最大限度的减少部署时间</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>Web容量规划的艺术 <a href="https://book.douban.com/subject/4200645/" target="_blank" rel="noopener">https://book.douban.com/subject/4200645/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;当我们在做大促，类似于双十一的活动时候，老板就会跑过来问我们这些问题&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1.线上服务能承受多大的访问量&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2.单台服务器能承受多大的访问量&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3.需要加机器吗？需要加多少台机器&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="架构设计" scheme="http://caolinhua.me/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>技术管理</title>
    <link href="http://caolinhua.me/2017/12/03/%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86/"/>
    <id>http://caolinhua.me/2017/12/03/技术管理/</id>
    <published>2017-12-02T16:00:00.000Z</published>
    <updated>2018-04-15T07:50:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>不论项目大小，一定要有目标，有目标才能让所有人看到方向，明确每天工作的意义。单纯技术人员应该切换思维为全局性，而不局限于技术层面，现在个人的成功而不是成功，团队的成功才算最终的成功，应该多思考怎么样才能让团队高质量的绩效产出。</p><a id="more"></a><h1 id="技术管理"><a href="#技术管理" class="headerlink" title="技术管理"></a>技术管理</h1><p>最近一直在思考技术转管理过程中需要注意到的一些事情，现在就总结下分享给大家看看</p><h1 id="核心职责"><a href="#核心职责" class="headerlink" title="核心职责"></a>核心职责</h1><h2 id="确定团队目标"><a href="#确定团队目标" class="headerlink" title="确定团队目标"></a>确定团队目标</h2><p>不论项目大小，一定要有目标，有目标才能让所有人看到方向，明确每天工作的意义。单纯技术人员应该切换思维为全局性，而不局限于技术层面，现在个人的成功而不是成功，团队的成功才算最终的成功，应该多思考怎么样才能让团队高质量的绩效产出。</p><h2 id="欠缺哪些资源"><a href="#欠缺哪些资源" class="headerlink" title="欠缺哪些资源"></a>欠缺哪些资源</h2><p>项目开始时候，需明确知道目前团队有哪些资源，比如人员，技术风险点及物理硬件采集。只有了解了需要哪些资源，我们才能更好的完成定下的团队目标</p><h2 id="怎么实现这个目标"><a href="#怎么实现这个目标" class="headerlink" title="怎么实现这个目标"></a>怎么实现这个目标</h2><p>这个在整个项目过程中都有所体现，具体怎么实现，我们可以拆分为三大块</p><ul><li>业务管理</li><li>团队管理</li><li>技术管理</li></ul><h3 id="业务管理"><a href="#业务管理" class="headerlink" title="业务管理"></a>业务管理</h3><p>业务管理，主要就是管理我们需要处理的业务需求。其实我们可分为这几大块</p><h4 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h4><ul><li>每天的任务分配与分解</li><li>制定大致的开发排期</li><li>每天了解开发进度</li><li>讨论与跟进各种具体的技术问题</li><li>协调一些产品需求变更</li><li>响应一些市场同事的需求</li><li>跟进功能上线</li></ul><h4 id="敏捷"><a href="#敏捷" class="headerlink" title="敏捷"></a>敏捷</h4><p>关于敏捷开发，针对不一样的团队、不同的产品，具体实践方式是不同的。不过重要的是每过段时间，需要做总结，来反思过去的一段时间中，是否出现变坏的趋势，然后在针对性的改进。总结下「敏捷是态度而不是流程，是氛围而不是方法」。</p><p>具体实践有下面 4 个部分组成</p><ul><li>计划会议</li><li>每日站会</li><li>评审会议</li><li>回顾会议</li></ul><h4 id="困难"><a href="#困难" class="headerlink" title="困难"></a>困难</h4><p>困难的地方很多，或者说当坐上管理岗位后，承担的责任就变重很多，体现在以下 5 个方面</p><ul><li>需求变更</li><li>线上紧急事故处理</li><li>业务临时需求</li><li>跨部门沟通</li><li>开发进度风险</li></ul><h4 id="心得"><a href="#心得" class="headerlink" title="心得"></a>心得</h4><ul><li>及时试用产品</li><li>观察燃尽图</li><li>多沟通</li></ul><h4 id="花费时间"><a href="#花费时间" class="headerlink" title="花费时间"></a>花费时间</h4><ul><li>40% - 60%</li></ul><h3 id="团队管理"><a href="#团队管理" class="headerlink" title="团队管理"></a>团队管理</h3><h4 id="招人"><a href="#招人" class="headerlink" title="招人"></a>招人</h4><ul><li>前同事</li><li>内部推荐</li><li>技术分享</li></ul><h4 id="带人"><a href="#带人" class="headerlink" title="带人"></a>带人</h4><ul><li>指导新人<ul><li>工作上指导<ul><li>技术细节讲解<ul><li>code review</li><li>工作方式与态度</li></ul></li></ul></li></ul></li><li>非工作上的帮助<ul><li>mentor要与新人成为朋友</li></ul></li><li>如果一件事情你熟悉了，不要做，交给新人做<ul><li>鼓励新人提问</li></ul></li><li>一对一沟通<ul><li>建立舒适的沟通环境<ul><li>保持真诚</li><li>让对方主动说，适当引导</li><li>沟通频率</li><li>沟通时长</li><li>构建私密，轻松，真诚，有效的环境，两个人一起讨论问题与互相学习</li></ul></li></ul></li><li>团队活动</li></ul><h4 id="花费时间-1"><a href="#花费时间-1" class="headerlink" title="花费时间"></a>花费时间</h4><ul><li>30%</li></ul><h3 id="技术管理-1"><a href="#技术管理-1" class="headerlink" title="技术管理"></a>技术管理</h3><h4 id="内容-1"><a href="#内容-1" class="headerlink" title="内容"></a>内容</h4><ul><li>技术架构是否合理？</li><li>流量增长，现在架构能否胜任</li><li>活动期间，突发流量多少，能否承受压力</li><li>未来架构如何变化</li><li>客户端投入哪些技术方案</li></ul><h4 id="建立有技术追求的团队"><a href="#建立有技术追求的团队" class="headerlink" title="建立有技术追求的团队"></a>建立有技术追求的团队</h4><ul><li>推进技术wiki的使用</li><li>推进技术分享</li><li>推进code review</li><li>推进追求代码质量</li></ul><h4 id="思考技术上的挑战，提前做准备"><a href="#思考技术上的挑战，提前做准备" class="headerlink" title="思考技术上的挑战，提前做准备"></a>思考技术上的挑战，提前做准备</h4><h4 id="花费时间-2"><a href="#花费时间-2" class="headerlink" title="花费时间"></a>花费时间</h4><ul><li>10%</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不论项目大小，一定要有目标，有目标才能让所有人看到方向，明确每天工作的意义。单纯技术人员应该切换思维为全局性，而不局限于技术层面，现在个人的成功而不是成功，团队的成功才算最终的成功，应该多思考怎么样才能让团队高质量的绩效产出。&lt;/p&gt;
    
    </summary>
    
    
      <category term="研发管理" scheme="http://caolinhua.me/tags/%E7%A0%94%E5%8F%91%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>分布式一致性想法</title>
    <link href="http://caolinhua.me/2017/11/27/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E6%83%B3%E6%B3%95/"/>
    <id>http://caolinhua.me/2017/11/27/分布式一致性的想法/</id>
    <published>2017-11-26T16:00:00.000Z</published>
    <updated>2018-04-15T07:52:54.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近一直在思考，工作这么多年下遇到的分布式系统的一下问题，以及针对这些问题提供的解决方案。<br>借这个机会，顺便梳理清楚这块知识，希望同大家一起探讨下</p><a id="more"></a><h2 id="常见一致性问题"><a href="#常见一致性问题" class="headerlink" title="常见一致性问题"></a>常见一致性问题</h2><h3 id="下订单减库存"><a href="#下订单减库存" class="headerlink" title="下订单减库存"></a>下订单减库存</h3><p>在我们做的电商系统中，会有这样的一个场景：用户下单购买某个商品，然后进行扣减商品库存的场景。</p><ul><li>如果先下订单，然后扣减库存，会导致<strong>超卖</strong></li><li>如果下订单失败，扣减库存成功，那么会导致<strong>少卖</strong></li></ul><p>这两种情况的发生都会导致我们系统出现一致性的问题，严重的话，需要对用户做出一定的经济补偿。</p><h3 id="调用超时"><a href="#调用超时" class="headerlink" title="调用超时"></a>调用超时</h3><p>业务开发的过程中，肯定会有我们维护的服务调用其他团队的服务，即使在机房内部进行网络调用，也或多或少的存在系统调用超时的现象，如果出现这样的现象，我们该怎么解决呢？</p><h2 id="解决一致性问题的思路"><a href="#解决一致性问题的思路" class="headerlink" title="解决一致性问题的思路"></a>解决一致性问题的思路</h2><h3 id="酸碱中和"><a href="#酸碱中和" class="headerlink" title="酸碱中和"></a>酸碱中和</h3><p>ACID ： 酸， BASE：碱，其实就是酸碱中和的原理</p><h4 id="1-ACID"><a href="#1-ACID" class="headerlink" title="1. ACID"></a>1. ACID</h4><p>ACID，是指数据库管理系统在写入数据过程中，为保证事务是正确可靠性。<br>所必须具备的四个特性：</p><ul><li>A: Atomicity 原子性 一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节</li><li>C: Consistency 一致性 事务开始之前和事务结束以后，数据库的完整性没有被破坏</li><li>I: Isolation 隔离性 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）</li><li>D: Durability 持久性 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失</li></ul><p>像 MySQL、Oracle 这样关系型数据库是支持 ACID 特性的强一致性要求的。本身强一致性就不允许出现不一致性的问题，底层都是通过 MVCC 来控制实现的</p><p>刚刚上面提到的下订单减库存就可以关系型数据库的强一致性来解决。将订单表与库存表放在一个数据库 Instance 中，通过数据库 ACID 的特性来解决少卖或者超卖的问题。</p><p>但是如果遇到数据量比较大的情况怎么办？订单表有多张，我们该怎么解决呢？</p><p>其实，即使遇到订单表进行拆分，我们可以仍然采用数据库 ACID 的特性来解决。怎么弄？我们可以将订单表的拆表维度与库存表的拆分维度控制在一个数据分片中，但是具体怎么拆分呢？需要各位根据自己的业务规则来划分开来</p><h4 id="2-BASE"><a href="#2-BASE" class="headerlink" title="2. BASE"></a>2. BASE</h4><p>BASE 思想解决了 CAP 提出的分布式一致性与可用性不能同时兼顾的问题。BASE 思想与 ACID 思想截然不同，它其实是满足 CAP 理论，通过牺牲强一致性来换取可用性。<br>BASE 理论：</p><ul><li>BA：Basically Available，基本可用性</li><li>S: Soft State 软状态 接受状态在一段时间内部同步</li><li>E：Eventually Consistent 最终一致性 在一定的时间窗口中，最终数据达成一致即可</li></ul><p>软状态是实现 BASE 的方法，基本可用域最终一致性是必须到达的目标。以 BASE 的思想由于不保证强一致性，所有接受系统在一定时间内数据存在不一致，不过在处理请求的过程中，需要记录知道每次请求的状态，以后出现问题的时候，回滚到中间任何临时状态，达到最终一致性</p><h4 id="3-CAP"><a href="#3-CAP" class="headerlink" title="3. CAP"></a>3. CAP</h4><p>当我们服务发展越来越多，是不可避免就会需要将服务进行拆分。一旦服务进行拆分后，它就不在是一个单机的系统，而是通俗意义上的分布式系统。说到分布式系统，我们一定要说下最为经典的帽子理论。如果我都没有听说过帽子理论，我出门都不好意思打招呼。<br>分布式系统 CAP 理论：</p><ul><li>C: Consistence 一致性 所有节点访问同一份最新的数据副本</li><li>A: Availability 可用性 每次请求都能在有限的时间内获取到响应——但是不保证获取的数据为最新数据</li><li>P: Network partitioning 分区容错性 尽管网络上有部分消息丢失，但仍然可以继续工作</li></ul><p>CAP 原理证明：分布式系统只能满足三项中的两项而不可能满足全部三项。理解 CAP 理论的最简单方式就是想象两个节点处在 2 个机房中。允许至少一个节点更新状态会导致数据不一致，即丧失了 C 性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了 A 性质。除非两个节点可以互相通信，才能既保证C 又保证 A，这又会导致丧失P性质。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本次文章介绍 ACID、CAP 和 BASE 思想。在传统数据库领域中采用 ACID 理论，追求强一致性。但是在大型分布式系统中，采用 BASE 的设计思想，通过牺牲强一致性来获取高可用性及最终的一致性。两种设计理念截然不同，大家需要根据自己的业务场景，来决定到底哪用方式。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>分布式服务架构原理、设计与实战</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;最近一直在思考，工作这么多年下遇到的分布式系统的一下问题，以及针对这些问题提供的解决方案。&lt;br&gt;借这个机会，顺便梳理清楚这块知识，希望同大家一起探讨下&lt;/p&gt;
    
    </summary>
    
    
      <category term="架构设计" scheme="http://caolinhua.me/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="分布式" scheme="http://caolinhua.me/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>架构设计思路</title>
    <link href="http://caolinhua.me/2017/11/19/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF/"/>
    <id>http://caolinhua.me/2017/11/19/架构设计思路/</id>
    <published>2017-11-18T16:00:00.000Z</published>
    <updated>2018-04-15T07:50:33.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们一般在做架构设计的时候，会经历过三个阶段：需求分析、概要设计和详细设计。</p><ol><li><strong>需求分析阶段</strong>：主要梳理所有用例（Use case）和场景，并抽象出面向系统的用户与角色，梳理出需求提供哪些功能与非功能的需求给这些用户。</li><li><strong>概要设计阶段</strong>：根据需求分析的产物：核心需求，对整个系统进行模块划分，并定义好模块之间的交互关系。</li><li><strong>详细设计阶段</strong>：通过多个视图来描述系统的架构，包括但不局限于：逻辑系统、物理视图、数据视图、物理视图<a id="more"></a></li></ol><h2 id="非功能需求"><a href="#非功能需求" class="headerlink" title="非功能需求"></a>非功能需求</h2><p>非功能的需求主要体现在高性能、高可用、可伸缩、可扩展、安全性等维度。</p><table><thead><tr><th>非功能指标</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td>高性能</td><td style="text-align:center">运行效率高、响应速度快、吞吐量高</td></tr><tr><td>可用性</td><td style="text-align:center">缩短宕机时间、出错恢复、SLA 在线可用时间</td></tr><tr><td>可伸缩性</td><td style="text-align:center">垂直伸缩、水平伸缩</td></tr><tr><td>可扩展性</td><td style="text-align:center">可插拔、组件重用</td></tr><tr><td>安全性</td><td style="text-align:center">数据安全、加密、防攻击</td></tr><tr><td>鲁棒性</td><td style="text-align:center">容错性、可恢复性</td></tr></tbody></table><h2 id="非功能需求对应不同系统指标"><a href="#非功能需求对应不同系统指标" class="headerlink" title="非功能需求对应不同系统指标"></a>非功能需求对应不同系统指标</h2><p>非功能需求对应不同系统指标主要分为 4 部分：</p><ul><li>应用服务器</li><li>数据库</li><li>缓存</li><li>消息队列</li></ul><h3 id="1-应用服务器"><a href="#1-应用服务器" class="headerlink" title="1. 应用服务器"></a>1. 应用服务器</h3><p>应用服务器是请求的入口，所有流量都是通过应用服务器来转发的。主要关心 QPS 、RT 等指标。<br>容量与性能相关指标如下所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1. 每天的请求量</span><br><span class="line">2. 各接口的访问峰值</span><br><span class="line">3. 平均响应时间</span><br><span class="line">4. 最大响应时间</span><br><span class="line">5. 请求大小</span><br><span class="line">6. 网卡与磁盘 I/O 负责</span><br><span class="line">7. 内存使用情况</span><br><span class="line">8. CPU 使用情况</span><br></pre></td></tr></table></figure><h3 id="2-数据库"><a href="#2-数据库" class="headerlink" title="2. 数据库"></a>2. 数据库</h3><p>部署结构相关指标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. 复制模型</span><br><span class="line">2. 失效转移策略</span><br><span class="line">3. 容灾策略</span><br><span class="line">4. 归档策略</span><br><span class="line">5. 读写分离策略</span><br><span class="line">6. 分库分表策略</span><br></pre></td></tr></table></figure><p>容量与性能相关指标如下所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 当前数据容量</span><br><span class="line">2. 预估数据容量</span><br><span class="line">3. 每秒读峰值</span><br><span class="line">4. 每秒写峰值</span><br><span class="line">5. 每秒事务峰值</span><br></pre></td></tr></table></figure><h3 id="3-缓存"><a href="#3-缓存" class="headerlink" title="3. 缓存"></a>3. 缓存</h3><p>部署结构相关指标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 复制模型</span><br><span class="line">2. 失效转移</span><br><span class="line">3. 持久策略</span><br><span class="line">4. 淘汰策略</span><br><span class="line">5. 线程模型</span><br></pre></td></tr></table></figure><p>容量与性能相关指标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. 缓存内容大小</span><br><span class="line">2. 缓存内容数量</span><br><span class="line">3. 缓存内容过期时间</span><br><span class="line">4. 缓存数据结构</span><br><span class="line">5. 每秒读峰值</span><br><span class="line">6. 每秒写峰值</span><br></pre></td></tr></table></figure><h3 id="4-消息队列"><a href="#4-消息队列" class="headerlink" title="4. 消息队列"></a>4. 消息队列</h3><p>部署结构相关指标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 复制模型</span><br><span class="line">2. 失效转移</span><br><span class="line">3. 持久策略</span><br></pre></td></tr></table></figure><p>容量与性能相关指标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1. 每天平均数据增量</span><br><span class="line">2. 消息保存时间</span><br><span class="line">3. 每秒读峰值</span><br><span class="line">4. 每秒写峰值</span><br><span class="line">5. 每条消息大小</span><br><span class="line">6. 平均响应时间</span><br><span class="line">7. 最大响应时间</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>分布式服务架构原理、设计与实战 </li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;我们一般在做架构设计的时候，会经历过三个阶段：需求分析、概要设计和详细设计。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;需求分析阶段&lt;/strong&gt;：主要梳理所有用例（Use case）和场景，并抽象出面向系统的用户与角色，梳理出需求提供哪些功能与非功能的需求给这些用户。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;概要设计阶段&lt;/strong&gt;：根据需求分析的产物：核心需求，对整个系统进行模块划分，并定义好模块之间的交互关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;详细设计阶段&lt;/strong&gt;：通过多个视图来描述系统的架构，包括但不局限于：逻辑系统、物理视图、数据视图、物理视图
    
    </summary>
    
    
      <category term="架构设计" scheme="http://caolinhua.me/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>从 ELK 到 EFK 演进</title>
    <link href="http://caolinhua.me/2017/11/11/%E4%BB%8EELK%20%E5%88%B0%20EFK/"/>
    <id>http://caolinhua.me/2017/11/11/从ELK 到 EFK/</id>
    <published>2017-11-10T16:00:00.000Z</published>
    <updated>2018-04-15T07:49:39.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>作为中国最大的在线教育站点，目前沪江日志服务的用户包含网校，交易，金融，CCTalk 等多个部门的多个产品的日志搜索分析业务，每日产生的各类日志有好十几种，每天处理约10亿条（1TB）日志，热数据保留最近7天数据，冷数据永久保存。</p><a id="more"></a><h1 id="为什么做日志系统"><a href="#为什么做日志系统" class="headerlink" title="为什么做日志系统"></a>为什么做日志系统</h1><blockquote><p>首先，什么是日志？ <strong>日志就是程序产生的，遵循一定格式（通常包含时间戳）的文本数据</strong></p></blockquote><p>通常日志由服务器生成，输出到不同的文件中，一般会有系统日志、 应用日志、安全日志。这些日志分散地存储在不同的机器上。</p><p>通常当系统发生故障时，工程师需要登录到各个服务器上，使用 grep / sed / awk 等 Linux 脚本工具去日志里查找故障原因。在没有日志系统的情况下，首先需要定位处理请求的服务器，如果这台服务器部署了多个实例，则需要去每个应用实例的日志目录下去找日志文件。每个应用实例还会设置日志滚动策略（如：每天生成一个文件），还有日志压缩归档策略等。</p><p>这样一系列流程下来，对于我们排查故障以及及时找到故障原因，造成了比较大的麻烦。因此，如果我们能把这些日志集中管理，并提供集中检索功能，不仅可以提高诊断的效率，同时对系统情况有个全面的理解，避免事后救火的被动。</p><p>我认为，日志数据在以下几方面具有非常重要的作用：</p><ul><li><strong>数据查找</strong>：通过检索日志信息，定位相应的 bug ，找出解决方案</li><li><strong>服务诊断</strong>：通过对日志信息进行统计、分析，了解服务器的负荷和服务运行状态</li><li><strong>数据分析</strong>：可以做进一步的数据分析，比如根据请求中的课程 id ，找出 TOP10 用户感兴趣课程。</li></ul><p>针对这些问题，为了提供分布式的实时日志搜集和分析的监控系统，我们采用了业界通用的日志数据管理解决方案 - 它主要包括 Elasticsearch 、 Logstash 和 Kibana 三个系统。通常，业界把这套方案简称为ELK，取三个系统的首字母，但是我们实践之后将其进一步优化为EFK，F代表Filebeat，用以解决Logstash导致的问题。下面，我们展开详细介绍。</p><p>文中涉及的 ELK stack 版本是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Elasticsearch 5.2.2</span><br><span class="line">Logstash 5.2.2</span><br><span class="line">Kibana 5.2.2</span><br><span class="line">Filebeat 5.2.2</span><br><span class="line">Kafka 2.10</span><br></pre></td></tr></table></figure><p><img src="/img/Elastic.png" alt=""></p><p><strong>Logstash</strong> ：数据收集处理引擎。支持动态的从各种数据源搜集数据，并对数据进行过滤、分析、丰富、统一格式等操作，然后存储以供后续使用。</p><p><strong>Kibana</strong> ：可视化化平台。它能够搜索、展示存储在 Elasticsearch 中索引数据。使用它可以很方便的用图表、表格、地图展示和分析数据。</p><p><strong>Elasticsearch</strong> ：分布式搜索引擎。具有高可伸缩、高可靠、易管理等特点。可以用于全文检索、结构化检索和分析，并能将这三者结合起来。Elasticsearch 基于 Lucene 开发，现在使用最广的开源搜索引擎之一，Wikipedia 、StackOverflow、Github 等都基于它来构建自己的搜索引擎。</p><p><strong>Filebeat</strong> ：轻量级数据收集引擎。基于原先 Logstash-fowarder 的源码改造出来。换句话说：Filebeat就是新版的 Logstash-fowarder，也会是 ELK Stack 在 shipper 端的第一选择。</p><p>既然要谈 ELK 在沪江系统中的应用，那么 ELK 架构就不得不谈。本次分享主要列举我们曾经用过的 ELK 架构，并讨论各种架构所适合的场景和优劣供大家参考</p><h1 id="简单版架构"><a href="#简单版架构" class="headerlink" title="简单版架构"></a>简单版架构</h1><p><img src="http://on-img.com/chart_image/59d9a58ce4b0ef561378d581.png" alt="image"></p><p>这种架构下我们把 Logstash 实例与 Elasticsearch 实例直接相连。Logstash 实例直接通过 Input 插件读取数据源数据(比如 Java 日志， Nginx 日志等)，经过 Filter 插件进行过滤日志，最后通过 Output 插件将数据写入到 ElasticSearch 实例中。</p><p>这个阶段，日志的收集、过滤、输出等功能，主要由这三个核心组件组成 Input 、Filter、Output</p><p><strong>Input</strong>：输入，输入数据可以是 File 、 Stdin（直接从控制台输入） 、TCP、Syslog 、Redis 、Collectd 等</p><p><strong>Filter</strong>：过滤，将日志输出成我们想要的格式。Logstash 存在丰富的过滤插件：Grok 正则捕获、时间处理、JSON 编解码、数据修改 Mutate 。Grok 是 Logstash 中最重要的插件，强烈建议每个人都要使用 <a href="https://grokdebug.herokuapp.com/" target="_blank" rel="noopener">Grok Debugger</a> 来调试自己的 Grok 表达式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grok &#123;</span><br><span class="line">      match =&gt; [&quot;message&quot;, &quot;(?m)\[%&#123;LOGLEVEL:level&#125;\] \[%&#123;TIMESTAMP_ISO8601:timestamp&#125;\] \[%&#123;DATA:logger&#125;\] \[%&#123;DATA:threadId&#125;\] \[%&#123;DATA:requestId&#125;\] %&#123;GREEDYDATA:msgRawData&#125;&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Output</strong>：输出，输出目标可以是 Stdout （直接从控制台输出）、Elasticsearch 、Redis 、TCP 、File 等</p><p>这是最简单的一种ELK架构方式，Logstash 实例直接与 Elasticsearch 实例连接。优点是搭建简单，易于上手。建议供初学者学习与参考，不能用于线上的环境。</p><h1 id="集群版架构"><a href="#集群版架构" class="headerlink" title="集群版架构"></a>集群版架构</h1><p><img src="http://on-img.com/chart_image/59dc7213e4b017b4197b402b.png" alt="image"></p><p>这种架构下我们采用多个 Elasticsearch 节点组成 Elasticsearch 集群，由于 Logstash 与 Elasticsearch 采用集群模式运行，集群模式可以避免单实例压力过重的问题，同时在线上各个服务器上部署 Logstash Agent，来满足数据量不大且可靠性不强的场景。</p><p><strong>数据收集端</strong>：每台服务器上面部署 Logstash Shipper Agent 来收集当前服务器上日志，日志经过 Logstash Shipper 中 Input插件、Filter插件、Output 插件传输到 Elasticsearch 集群</p><p><strong>数据存储与搜索</strong>：Elasticsearch 配置默认即可满足，同时我们看数据重要性来决定是否添加副本，如果需要的话，最多一个副本即可</p><p><strong>数据展示</strong>：Kibana 可以根据 Elasticsearch 的数据来做各种各样的图表来直观的展示业务实时状况</p><p>这种架构使用场景非常有限，主要存在以下两个问题</p><ul><li><strong>消耗服务器资源</strong>：Logstash 的收集、过滤都在服务器上完成，这就造成服务器上占用系统资源较高、性能方面不是很好，调试、跟踪困难，异常处理困难</li><li><strong>数据丢失</strong>：大并发情况下，由于日志传输峰值比较大，没有消息队列来做缓冲，就会导致 Elasticsearch 集群丢失数据</li></ul><p>这个架构相对上个版本略微复杂，不过维护起来同样比较方便，同时可以满足数据量不大且可靠性不强的业务使用。</p><h1 id="引入消息队列"><a href="#引入消息队列" class="headerlink" title="引入消息队列"></a>引入消息队列</h1><p><img src="http://on-img.com/chart_image/59c9fa8ce4b0ef5613754b6b.png" alt="image"></p><p>该场景下面，多个数据首先通过 Lostash Shipper Agent 来收集数据，然后经过 Output 插件将数据投递到 Kafka 集群中，这样当遇到 Logstash 接收数据的能力超过 Elasticsearch 集群处理能力的时候，就可以通过队列就能起到削峰填谷的作用， Elasticsearch 集群就不存在丢失数据的问题。</p><p>目前业界在日志服务场景中，使用比较多的两种消息队列为 ：Kafka VS Redis。尽管 ELK Stack 官网建议使用 Redis 来做消息队列，但是我们建议采用 Kafka 。主要从下面两个方面考虑:</p><ul><li><strong>数据丢失</strong>：Redis 队列多用于实时性较高的消息推送，并不保证可靠。Kafka保证可靠但有点延时</li><li><strong>数据堆积</strong>：Redis 队列容量取决于机器内存大小，如果超过设置的Max memory，数据就会抛弃。Kafka 的堆积能力取决于机器硬盘大小。</li></ul><p>综合上述的理由，我们决定采用 Kafka 来缓冲队列。不过在这种架构下仍然存在一系列问题</p><ul><li>Logstash shipper 收集数据同样会消耗 CPU 和内存资源</li><li>不支持多机房部署</li></ul><p>这种架构适合较大集群的应用部署，通过消息队列解决了消息丢失、网络堵塞的问题。</p><h1 id="多机房部署"><a href="#多机房部署" class="headerlink" title="多机房部署"></a>多机房部署</h1><p><img src="http://on-img.com/chart_image/59d9bb57e4b0ef561378da2a.png" alt="image"></p><p>随着沪江业务的飞速增长，单机房的架构已经不能满足需求。不可避免的，沪江的业务需要分布到不同机房中，对于日志服务来说也是不小的挑战。当然业界也有不少成熟的方法，比如阿里的单元化、腾讯的 SET 方案等等。单元化在这边不详细展开，大家可以参考微博的<a href="http://www.infoq.com/cn/articles/how-weibo-do-unit-architecture" target="_blank" rel="noopener">【单元化架构】</a></p><p>最终我们决定采用单元化部署的方式来解决 ELK 多机房中遇到的问题(延时、专线流量过大等)，从日志的产生、收集、传输、存储、展示都是在同机房里面闭环消化，不存在跨机房传输与调用的问题。因为交互紧密的应用尽量部署在同机房，所以这种方案并不会给业务查询造成困扰。</p><p>Logstash、Elasticsearch、Kafka、Kibana 四个集群都部署到同一机房中，每个机房都要每个机房自己的日志服务集群，比如A机房业务的日志只能传输给本机房 Kafka ，而A机房 Indexer 集群消费并写入到A机房 Elasticsearch 集群中，并由A机房 Kibana 集群展示，中间任何一个步骤不依赖B机房任何服务。</p><h1 id="引入Filebeat"><a href="#引入Filebeat" class="headerlink" title="引入Filebeat"></a>引入Filebeat</h1><p><img src="http://on-img.com/chart_image/59d9ca40e4b0ef561378df53.png" alt="image"></p><p>Filebeat 是基于原先 logstash-forwarder 的源码改造出来的，无需依赖 Java 环境就能运行，安装包10M不到。</p><p>如果日志的量很大，Logstash 会遇到资源占用高的问题，为解决这个问题，我们引入了Filebeat。Filebeat 是基于 logstash-forwarder 的源码改造而成，用 Golang 编写，无需依赖 Java 环境，效率高，占用内存和 CPU 比较少，非常适合作为 Agent 跑在服务器上。</p><p>下面看看Filebeat的基本用法。编写配置文件，从 Nginx access.log 中解析日志数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># filebeat.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- input_type: log</span><br><span class="line">  paths: /var/log/nginx/access.log</span><br><span class="line">  json.message_key:</span><br><span class="line"></span><br><span class="line">output.elasticsearch:</span><br><span class="line">  hosts: [&quot;localhost&quot;]</span><br><span class="line">  index: &quot;filebeat-nginx-%&#123;+yyyy.MM.dd&#125;&quot;</span><br></pre></td></tr></table></figure><p>我们来看看压测数据</p><h3 id="压测环境"><a href="#压测环境" class="headerlink" title="压测环境"></a>压测环境</h3><ul><li>虚拟机 8 cores 64G内存 540G SATA盘</li><li>Logstash 版本 2.3.1</li><li>Filebeat 版本 5.5.0</li></ul><h3 id="压测方案"><a href="#压测方案" class="headerlink" title="压测方案"></a>压测方案</h3><p>Logstash / Filebeat 读取 350W 条日志 到 console，单行数据 580B，8个进程写入采集文件</p><h3 id="压测结果"><a href="#压测结果" class="headerlink" title="压测结果"></a>压测结果</h3><table><thead><tr><th>项目</th><th>workers</th><th>cpu usr</th><th>总共耗时</th><th>收集速度</th></tr></thead><tbody><tr><td>Logstash</td><td>8</td><td>53.7%</td><td>210s</td><td>1.6w line/s</td></tr><tr><td>Filebeat</td><td>8</td><td>38.0%</td><td>30s</td><td>11w line/s</td></tr></tbody></table><p>Filebeat 所消耗的CPU只有 Logstash 的70%，但收集速度为 Logstash 的7倍。从我们的应用实践来看，Filebeat 确实用较低的成本和稳定的服务质量，解决了 Logstash 的资源消耗问题。</p><p>最后，分享给大家一些血泪教训，希望大家以我为鉴。</p><h4 id="1-Indexer-运行一段时间后自动挂掉"><a href="#1-Indexer-运行一段时间后自动挂掉" class="headerlink" title="1. Indexer 运行一段时间后自动挂掉"></a>1. Indexer 运行一段时间后自动挂掉</h4><p>突然有一天监控发现日志不消费了，排查下来发现消费Kafka数据的indexer 挂掉了。所以，Indexer 进程也是需要用 supervisor 来监控的，保证它时刻都在运行。</p><h4 id="2-Java异常日志输出"><a href="#2-Java异常日志输出" class="headerlink" title="2. Java异常日志输出"></a>2. Java异常日志输出</h4><p>开始我们在通过 grok 切割日志的时候，发现Java 的 Exception 日志输出之后，会出现换行的问题。后来使用 Logstash <strong>codec/multiline</strong> 插件来解决。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    stdin &#123;</span><br><span class="line">        codec =&gt; multiline &#123;</span><br><span class="line">            pattern =&gt; &quot;^\[&quot;</span><br><span class="line">            negate =&gt; true</span><br><span class="line">            what =&gt; &quot;previous&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-由于时区导致日志8小时时差"><a href="#3-由于时区导致日志8小时时差" class="headerlink" title="3. 由于时区导致日志8小时时差"></a>3. 由于时区导致日志8小时时差</h4><p>Logstash 2.3版本 date插件配置如下，查看解析结果发现@timestamp比中国时间早了8小时。</p><p>解决方案 Kibana 读取浏览器的当前时区，然后在页面上转换时间内容的显示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">date &#123;</span><br><span class="line">  match =&gt; [ &quot;log_timestamp&quot;, &quot;YYYY-MM-dd HH:mm:ss.SSS&quot; ]</span><br><span class="line">  target =&gt; &quot;@timestamp&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-Grok-parse-failure"><a href="#4-Grok-parse-failure" class="headerlink" title="4.Grok parse failure"></a>4.Grok parse failure</h4><p>我们遇到线上node日志突然有几天日志查看不出来。后来拉出原始日志对比才发现生成出来的日志格式不正确，同时包含 JSON 格式和非 JSON格式的日志。但是我们用grok解析的时候采用是json格式。建议大家输出日志保证格式一致同时不要出现空格等异常字符，可以使用在线grok debug (<a href="http://grokdebug.herokuapp.com/" target="_blank" rel="noopener">http://grokdebug.herokuapp.com/</a>) 来调试正则。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>基于 ELK stack 的日志解决方案的优势主要体现于</p><ul><li>可扩展性：采用高可扩展性的分布式系统架构设计，可以支持每日 TB 级别的新增数据。</li><li>使用简单：通过用户图形界面实现各种统计分析功能，简单易用，上手快</li><li>快速响应：从日志产生到查询可见，能达到秒级完成数据的采集、处理和搜索统计。</li><li>界面炫丽：Kibana 界面上，只需要点击鼠标，就可以完成搜索、聚合功能，生成炫丽的仪表板</li></ul><p><img src="/img/dfs.png" alt=""></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://www.elastic.co/guide/en/beats/filebeat/1.3/filebeat-overview.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/1.3/filebeat-overview.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/26399963" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26399963</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;作为中国最大的在线教育站点，目前沪江日志服务的用户包含网校，交易，金融，CCTalk 等多个部门的多个产品的日志搜索分析业务，每日产生的各类日志有好十几种，每天处理约10亿条（1TB）日志，热数据保留最近7天数据，冷数据永久保存。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="http://caolinhua.me/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="ELK" scheme="http://caolinhua.me/tags/ELK/"/>
    
      <category term="Elasticsearch" scheme="http://caolinhua.me/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Exception总结</title>
    <link href="http://caolinhua.me/2017/09/24/Exception%E6%80%BB%E7%BB%93/"/>
    <id>http://caolinhua.me/2017/09/24/Exception总结/</id>
    <published>2017-09-23T16:00:00.000Z</published>
    <updated>2018-04-15T07:52:25.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Empty集合处理"><a href="#Empty集合处理" class="headerlink" title="Empty集合处理"></a>Empty集合处理</h3><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>函数是应当返回null还是长度为0的数组（或集合）？</p><a id="more"></a><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>返回零长度的数组或集合而不是null</p><h4 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h4><p>如果返回empty，就可以少了很多NOT-NULL判断<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Person&gt; list = queryPerson();  </span><br><span class="line">if (list != null) &#123;  </span><br><span class="line">    for (Person p : list) &#123;  </span><br><span class="line">        //do something  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果queryPerson永不返回null，那代码可以这样（如果有粗心的程序员或者自己忘了判断null）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Person&gt; list = queryPerson();  </span><br><span class="line">for (Person p : list) &#123;  </span><br><span class="line">    //do something  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>遵守这个规则的一个例子就是Spring JdbcTemplate的query方法，在查询不到结果时，返回的是empty List： RowMapperResultSetExtractor<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public List&lt;T&gt; extractData(ResultSet rs) throws SQLException &#123;  </span><br><span class="line">    List&lt;T&gt; results = (this.rowsExpected &gt; 0 ? new ArrayList&lt;T&gt;(this.rowsExpected) : new ArrayList&lt;T&gt;());  </span><br><span class="line">    int rowNum = 0;  </span><br><span class="line">      </span><br><span class="line">    while (rs.next()) &#123;  </span><br><span class="line">        results.add(this.rowMapper.mapRow(rs, rowNum++));  </span><br><span class="line">    &#125;  </span><br><span class="line">    return results;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="Exception实践"><a href="#Exception实践" class="headerlink" title="Exception实践"></a>Exception实践</h3><h4 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h4><p>什么时候用Exception呢？</p><h4 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h4><ol><li>异常不应该被用来控制正常的控制流,但可以用来替换不正常的控制流。</li><li>正常的业务流程分支中不能用异常来控制，但是业务流程的不可恢复动作或者结束可以采用异常来处理<h4 id="举例-1"><a href="#举例-1" class="headerlink" title="举例"></a>举例</h4>用户登录失败，如果查询不到用户，就通过异常返回<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">User user = dao.getUser();</span><br><span class="line">if (user != null) &#123;</span><br><span class="line">    throw new UserNotExistExcption(&quot;User not exist&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>注册用户,如果手机号不存在，就创建新用户<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String mobile = 1234</span><br><span class="line">User user = dao.getUser(mobile);</span><br><span class="line">if (user == null) &#123;</span><br><span class="line">    dao.registerUser(mobile);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h3><p>什么时候使用Checked Exception还是UnChecked Exception？</p><h4 id="结论-2"><a href="#结论-2" class="headerlink" title="结论"></a>结论</h4><ol><li>如果你希望强制你的类调用者来处理异常，那么就用Checked Exception</li><li>如果你不希望强制你的类调用者来处理异常，就用Runtime Exception。<br>具体什么时候使用强制还是不强制呢，权衡的依据来自于从业务系统角度出发，如果业务规则定义了调用者应该处理，那么就必须Checked，如果业务规则没有定义，就应该用Runtime Exception<h4 id="举例-2"><a href="#举例-2" class="headerlink" title="举例"></a>举例</h4>用户登陆的例子，可能会产生下面这些异常</li></ol><ul><li>IOException (例如读取配置文件找不到) </li><li>SQLException (例如连接数据库错误) </li><li>ClassNotFoundException(找不到数据库驱动类) </li><li>NoSuchUserException (没有对应用户)</li><li>PasswordNotMatchException (密码匹配不上)</li></ul><p>上面3个异常是和业务逻辑无关的系统容错异常，所以应该转换为RuntimeException，不强制类调用者来处理(Spring已经帮我们在框架层面转为Runtime Exception)；而下面两个异常是和业务逻辑相关的流程，从业务实现的角度来说，类调用者必须处理，所以要Checked，强迫调用者去处理(针对提供给外部服务的SDK)。<br>至于上层调用者catch到NoSuchUserException和PasswordNotMatchException怎么处理，也要根据他自己具体的业务逻辑了。如果他有能力处理，就自己处理掉了；或者他不关心这个异常，也不希望上面的类调用者关心，就转化为RuntimeException；或者他希望上面的类调用者处理，而不是自己处理，就转化为本层的异常继续往上抛出来。</p><h3 id="《重构》这本书中关于正确使用-Exception-有两个重构方法："><a href="#《重构》这本书中关于正确使用-Exception-有两个重构方法：" class="headerlink" title="《重构》这本书中关于正确使用 Exception 有两个重构方法："></a>《重构》这本书中关于正确使用 Exception 有两个重构方法：</h3><ul><li>310 页：Replace Error Code with Exception </li><li>315 页：Replace Exception with Test <h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2></li></ul><ol><li>Best Practice for Exception Handling <a href="http://www.onjava.com/pub/a/onjava/2003/11/19/exceptions.html" target="_blank" rel="noopener">http://www.onjava.com/pub/a/onjava/2003/11/19/exceptions.html</a></li><li>JAVA 异常设计原则 <a href="http://www.iteye.com/topic/857443" target="_blank" rel="noopener">http://www.iteye.com/topic/857443</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Empty集合处理&quot;&gt;&lt;a href=&quot;#Empty集合处理&quot; class=&quot;headerlink&quot; title=&quot;Empty集合处理&quot;&gt;&lt;/a&gt;Empty集合处理&lt;/h3&gt;&lt;h4 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h4&gt;&lt;p&gt;函数是应当返回null还是长度为0的数组（或集合）？&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="http://caolinhua.me/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>一个项目怎么开发出来</title>
    <link href="http://caolinhua.me/2017/09/23/%E4%B8%80%E4%B8%AA%E9%A1%B9%E7%9B%AE%E6%80%8E%E4%B9%88%E5%BC%80%E5%8F%91%E5%87%BA%E6%9D%A5%E7%9A%84%EF%BC%9F/"/>
    <id>http://caolinhua.me/2017/09/23/一个项目怎么开发出来的？/</id>
    <published>2017-09-22T16:00:00.000Z</published>
    <updated>2018-04-15T07:51:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在尝试梳理我们日常工作中做项目的一些小结，下面就讲这些小结做一些简单分享与交流。首先，在我们做软件项目的过程中，一般项目中技术能力构成主要有下面三点</p><ul><li>工程能力</li><li>关键技术能力</li><li>架构能力<a id="more"></a>不管技术是否复杂，架构是否混乱，工程能力对于任何一个项目是必不可少的。所以下面我就分享一下这几年在大型公司中实施工程方面的一些总结和经验，同样适用于一些中小型公司。<h3 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h3></li></ul><blockquote><p>目标 – 原则 – 方法 – 结果</p></blockquote><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>目标，做一件事情的目标，是为了解决什么问题。<br>做软件项目，同样需要明白做这个项目的目标是什么，它解决了什么问题。</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>方法，解决一件事情的方式多种多样，这里不拘泥于任何形式。<br>在互联网的这几年里面，让我看清一个事实。即使互联网爆发力强，但是靠技术改变革命的产品，只有很小一部分，其他的工作都是很苦逼的体力活。</p><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>结果，通过方法实现目标后的结果<br>需要明确的是，这里的结果需要和目标一一对应的看，否则结果没有意义，说明不问题。<br>比如</p><ul><li>调取软件项目上线前后同周期数据对比</li><li>如果为新项目没有对比数据，则调取业界数据进行对比</li><li>优化项目需提前收集好数据，以便上线后获取上线前后的数据对比</li></ul><p>总体思路其实就是上面几个，具体到执行方面的话，就有下面八个主要步骤</p><h4 id="一、项目立项"><a href="#一、项目立项" class="headerlink" title="一、项目立项"></a>一、项目立项</h4><ul><li>目标与价值</li><li>定位与边界</li></ul><h4 id="二、设计评审"><a href="#二、设计评审" class="headerlink" title="二、设计评审"></a>二、设计评审</h4><ul><li>整体概要设计</li><li>详细API与表设计</li></ul><h4 id="三、开发阶段"><a href="#三、开发阶段" class="headerlink" title="三、开发阶段"></a>三、开发阶段</h4><ul><li>仓库管理git workflow</li><li>代码review</li><li>单元测试与集成测试</li><li>sonar代码分析</li></ul><h2 id="四、测试阶段"><a href="#四、测试阶段" class="headerlink" title="四、测试阶段"></a>四、测试阶段</h2><ul><li>功能性测试</li><li>性能测试</li><li>破坏性测试</li></ul><h2 id="五、部署阶段"><a href="#五、部署阶段" class="headerlink" title="五、部署阶段"></a>五、部署阶段</h2><ul><li>服务器无单点部署</li><li>服务器无状态</li><li>多机房部署</li></ul><h2 id="六、服务监控"><a href="#六、服务监控" class="headerlink" title="六、服务监控"></a>六、服务监控</h2><ul><li>机器监控</li><li>中间件监控</li><li>应用监控</li><li>业务监控</li></ul><h2 id="七、项目管理"><a href="#七、项目管理" class="headerlink" title="七、项目管理"></a>七、项目管理</h2><h3 id="Jira关联项目进度"><a href="#Jira关联项目进度" class="headerlink" title="Jira关联项目进度"></a>Jira关联项目进度</h3><p>通过Jira关注整体的进度，如果遇到出现任务delay了，需要及时跟进沟通，确保每个环境都没有问题</p><h3 id="站立会议"><a href="#站立会议" class="headerlink" title="站立会议"></a>站立会议</h3><p>每天早上进行10分钟左右的站会，主要说明昨天做什么，今天要做什么，以及遇到了什么问题</p><h2 id="八、结果反馈"><a href="#八、结果反馈" class="headerlink" title="八、结果反馈"></a>八、结果反馈</h2><ul><li>性能层面数据对比</li><li>产品层面数据对比</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在尝试梳理我们日常工作中做项目的一些小结，下面就讲这些小结做一些简单分享与交流。首先，在我们做软件项目的过程中，一般项目中技术能力构成主要有下面三点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;工程能力&lt;/li&gt;
&lt;li&gt;关键技术能力&lt;/li&gt;
&lt;li&gt;架构能力
    
    </summary>
    
    
      <category term="技术" scheme="http://caolinhua.me/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="项目管理" scheme="http://caolinhua.me/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>搜索平台化之路</title>
    <link href="http://caolinhua.me/2017/07/23/%E6%90%9C%E7%B4%A2%E5%AE%9E%E8%B7%B5/"/>
    <id>http://caolinhua.me/2017/07/23/搜索实践/</id>
    <published>2017-07-22T16:00:00.000Z</published>
    <updated>2018-04-15T07:51:27.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>随着公司业务的高速发展以及数据爆炸式的增长，当前公司各产线都有关于搜索方面的需求，但是以前的搜索服务系统由于架构与业务上的设计，不能很好的满足各个业务线的期望，主要体现下面三个问题：</p><ol><li>不能支持对语句级别的搜索，大量业务相关的属性根本无法实现</li><li>没有任何搜索相关的指标评价体系</li><li>扩展性与维护性特别差<a id="more"></a></li></ol><p>基于现状，对行业内的搜索服务做出充分调研，确认使用ElasticSearch做底层索引存储，同时重新设计现有搜索服务，使其满足业务方对维护性、定制化搜索排序方面的需求。</p><h3 id="整体技术架构"><a href="#整体技术架构" class="headerlink" title="整体技术架构"></a>整体技术架构</h3><p>沪江搜索服务底层基于分布式搜索引擎ElasticSearch，ElasticSearch是一个基于Lucene构建的开源，分布式，Restful搜索引擎；能够达到近实时搜索，稳定，可靠，快速响应的要求。</p><p><img src="https://public.lightpic.info/image/EDAF_593171290.jpg" alt="image"></p><p>搜索服务整体分为5个子系统</p><ul><li>搜索服务(Search Server) : 提供搜索与查询的功能</li><li>更新服务(Index Server)  : 提供增量更新与全量更新的功能</li><li>Admin 控制台 : 提供UI界面，方便索引相关的维护操作</li><li>ElasticSearch存储系统 : 底层索引数据存储服务</li><li>监控平台: 提供基于ELK日志与zabbix的监控</li></ul><h3 id="外部系统接口设计"><a href="#外部系统接口设计" class="headerlink" title="外部系统接口设计"></a>外部系统接口设计</h3><p><img src="https://public.lightpic.info/image/995C_5931733E0.jpg" alt="image"></p><ul><li>查询<ul><li>查询接口提供http的调用方式，当出现跨机房访问的时候，请使用http接口，其余都可以使用dubbo RPC调用</li></ul></li><li>增量更新<ul><li>数据增量更新接口采用提供MQ的方式接入。当业务方出现数据更新的时候，只需将数据推送到对应的MQ通道中即可。更新服务会监听每个业务方通道，及时将数据更新到ElasticSearch中</li></ul></li><li>全量索引<ul><li>更新服务会调用业务方提供的全量Http接口(该接口需提供分页查询等功能)<h3 id="全量更新"><a href="#全量更新" class="headerlink" title="全量更新"></a>全量更新</h3>众所周知，全量更新的功能在搜索服务中是必不可少的一环。它主要能解决以下三个问题</li></ul></li><li>业务方本身系统的故障，出现大量数据的丢失</li><li>业务高速发展产生增减字段或者修改分词算法等相关的需求</li><li>业务冷启动会有一次性导入大批量数据的需求</li></ul><p>基于上面提到的问题，我们与业务方合作实现了全量索引。但是在这个过程中，我们也发现一个通用的问题。在进行全量更新的时候，其实增量更新也在同时进行，如果这两种更新同时在进行的话，就会有遇到少量增量更新的数据丢失。比如说下面这个场景</p><ol><li>业务方发现自己搜索业务<strong>alias_A</strong>数据大量数据丢失，所以进行索引重建。其中alias_A是别名，就是我们通常说alias,但是底层真正的索引是index_201701011200(建议:索引里面包含时间属性，这样就能知道是什么创建的)</li><li>首先创建一个新的索引index_201706011200，然后从数据中拉出数据并插入ES中，并记录时间戳T1，最后索引完成的时间戳为T2，并切换搜索别名<strong>index_1</strong>指向index_201706011200。</li><li>索引创建成功之后的最新数据为T1这个时刻的，但是T1到T2这段时间的数据，并没有获取出来。同时index_201701011200老索引还在继续消费MQ中的数据，包括T1到T2时间内的缺少数据。</li><li>所以每次索引重建的时候，都会缺少<strong>T1</strong>到<strong>T2</strong>时间内的数据。</li></ol><p>最后，针对上面这个场景，我们提出通过zookeeper分布式锁来暂停index consumer的消费,具体步骤如下</p><ol><li>创建new_index </li><li>获取该index 对应的别名，来修改分布式锁的状态为stop</li><li>index consumer监控stop状态，暂停索引数据的更新</li><li>new_index索引数据创建完毕，更新分布式锁状态为start</li><li>index consumer监控start状态，继续索引数据的更新</li></ol><p><img src="https://public.lightpic.info/image/5E5F_593271040.jpg" alt="image"><br>这样的话，我们就不用担心在创建索引的这段时间内，数据会有缺少的问题。相信大家对于这种方式解决全量与增量更新数据有所体会。</p><h3 id="集群无缝扩容"><a href="#集群无缝扩容" class="headerlink" title="集群无缝扩容"></a>集群无缝扩容</h3><p>数据量爆炸式的增加，导致我们ES集群最终还是遇到了容量不足的问题。在此背景下，同时结合ES本身提供的无缝扩容功能，我们最终决定对线上ES集群进行了<strong>在线的无缝扩容</strong>，将从原来的3台机器扩容为5台，具体步骤如下</p><ul><li>扩容前准备<ul><li>目前我们线上已经有3台机器正在运行着，其中node1为master节点，node2和node3为data节点，节点通信采用单播的形式而非广播的方式。</li><li>准备2台(node4与node5)机器，其中机器本身配置与ES配置参数需保持一致</li></ul></li><li>扩容中增加节点<ul><li>启动node4与node5(注意一个一个启动),启动完成之后，查看node1,2,3,4,5节点状态，正常情况下node1,2,3节点都已发现node4与node5，并且各节点之间状态应该是一致的</li></ul></li><li>重启master node<ul><li>修改node1,2,3节点配置与node4,5保持一致，然后顺序重启node2与node3，一定要优先重启data node，最后我们在重启node1(master node).到此为止，我们的线上ES集群就在线无缝的扩容完毕</li></ul></li></ul><p><img src="https://public.lightpic.info/image/A02D_5932717D0.jpg" alt="image"></p><h3 id="部署优化"><a href="#部署优化" class="headerlink" title="部署优化"></a>部署优化</h3><ul><li>查询与更新服务分离<ul><li>查询服务与更新服务在部署上进行物理隔离，这样可以隔离更新服务的不稳定对查询服务的影响</li></ul></li><li>预留一半内存<ul><li>ES底层存储引擎是基于Lucene,Lucenede的倒排索引是先在内存中生成，然后定期以段的形式异步刷新到磁盘上，同时操作系统也会把这些段文件缓存起来，以便更快的访问。所以Lucene的性能取决于和OS的交互，如果你把所有的内存都分配给Elasticsearch，不留一点给Lucene，那你的全文检索性能会很差的。所有官方建议，预留一半以上内存给Lucene使用</li></ul></li><li>内存不要超过32G<ul><li>跨32G的时候，会出现一些现象使得内存使用率还不如低于32G，具体原因请参考官方提供的这篇文章 <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#compressed_oops" target="_blank" rel="noopener">Don’t Cross 32 GB!</a></li></ul></li><li>尽量避免使用wildcard<ul><li>其实使用wildcard查询，有点类似于在数据库中使用左右通配符查询。(如：*foo*z这样的形式)</li></ul></li><li>设置合理的刷新时间<ul><li>ES中默认index.refresh_interval参数为1s。对于大多数搜索场景来说，数据生效时间不需要这么及时，所以大家可以根据自己业务的容忍程度来调整</li></ul></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本章主要介绍公司搜索服务的整体架构，重点对全量更新中数据一致性的问题，ES在线扩容做了一定的阐述，同时列举了一些公司在部署ES上做的一些优化。本文主要目的，希望大家通过阅读沪江搜索实践，能够给广大读者带来一些关于搭建一套通用搜索的建议。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;随着公司业务的高速发展以及数据爆炸式的增长，当前公司各产线都有关于搜索方面的需求，但是以前的搜索服务系统由于架构与业务上的设计，不能很好的满足各个业务线的期望，主要体现下面三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不能支持对语句级别的搜索，大量业务相关的属性根本无法实现&lt;/li&gt;
&lt;li&gt;没有任何搜索相关的指标评价体系&lt;/li&gt;
&lt;li&gt;扩展性与维护性特别差
    
    </summary>
    
    
      <category term="技术" scheme="http://caolinhua.me/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Elasticsearch" scheme="http://caolinhua.me/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>分布式跟踪调研与设计</title>
    <link href="http://caolinhua.me/2017/07/23/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B7%9F%E8%B8%AA%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%A0%94/"/>
    <id>http://caolinhua.me/2017/07/23/分布式跟踪系统调研/</id>
    <published>2017-07-22T16:00:00.000Z</published>
    <updated>2018-04-15T07:49:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司业务由数以百计的分布式服务沟通，每一个请求路由过来后，会经过多个业务系统并留下足迹，并产生对各种缓存或者DB的访问，但是这些分散的数据对于问题排查，或者流程优化比较有限。对于一个跨进程的场景，汇总收集并分析海量日志就显得尤为重要。在这种架构下，跨进程的业务流会经过很多个微服务的处理和传递，我们难免会遇到这样的问题:</p><a id="more"></a><ul><li>一次请求的流量从哪个服务而来？ 最终落到了哪个服务中去？</li><li>为什么这个请求这么慢? 到底哪个环节出了问题? </li><li>这个操作需要依赖哪些东西? 是数据库还是消息队列? Redis挂了，哪些业务受影响?  </li></ul><p>对于这个问题，业内已经有了一些实践和解决方案，通过调用链的方式，把一次请求调用过程完整的串联起来，这样就实现了对请求条用路径的监控。在业界，Twitter的Zipkin和淘宝的鹰眼就是类似的系统，它们都起源于Google Dapper论文，就像历史上Hadoop起源于Google Map/Reduce论文，Hbase起源于Google BigTable论文一样</p><h1 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h1><ul><li>低消耗性：跟踪系统对业务系统的影响应该做到足够小。在一些高度优化过的服务，即使一点点损耗也容易察觉到，而且有可能迫使在线负责的部署团队不得不将跟踪系统关停</li><li>低侵入性：作为非业务组件，应当尽可能少侵入或者无侵入业务系统，对于使用方透明，减少开发人员的负担</li><li>时效性：从数据的收集产生，到数据计算处理，再到最终展现，都要求尽可能快</li><li>决策支持：这些数据是否能在决策支持层面发挥作用，特别是从DevOps的角度</li><li>数据可视化：做到不用看日志通过可视化进行筛选<h1 id="实现功能"><a href="#实现功能" class="headerlink" title="实现功能"></a>实现功能</h1></li><li>故障快速定位<ul><li>调用链路跟踪，一次请求的逻辑轨迹可以完整清晰的展示出来。</li></ul></li><li>各个调用环节的性能分析<ul><li>调用链的各个环节分表添加调用耗时，可以分析出系统的性能瓶颈，并针对性的优化。</li></ul></li><li>数据分析<ul><li>调用链是一条完整的业务日志，可以得到用户的行为路径，汇总分析应用在很多业务场景<h1 id="设计性能指标"><a href="#设计性能指标" class="headerlink" title="设计性能指标"></a>设计性能指标</h1></li></ul></li></ul><table><thead><tr><th>项目</th><th>指标</th></tr></thead><tbody><tr><td>kafka</td><td>&gt; 5000 Query Per Second</td></tr><tr><td>数据延迟</td><td>&lt; 1 Min</td></tr><tr><td>查询延迟</td><td>&lt; 3 Second</td></tr></tbody></table><h1 id="相关软件与硬件"><a href="#相关软件与硬件" class="headerlink" title="相关软件与硬件"></a>相关软件与硬件</h1><table><thead><tr><th>名称</th><th>数量</th><th>备注</th></tr></thead><tbody><tr><td>Kafka</td><td>1套3节点</td><td>与监控系统共用一套集群，分属不同Topic</td></tr><tr><td>ElasticSearch</td><td>1套3节点</td><td>与ELK共用一套集群，前提ELK需做扩容准备</td></tr><tr><td>API机器</td><td>虚拟机3台</td><td>公司标准虚拟机配置4core 8G即可</td></tr></tbody></table><h1 id="系统限制"><a href="#系统限制" class="headerlink" title="系统限制"></a>系统限制</h1><p>公司服务部署在多个机房中，但是分布式跟踪的数据需汇总收集并展示，故暂时进行采用不了多机房部署方案。考虑到分布式跟踪系统类似于ELK系统的基础服务，部署架构与现有ELK保证一致，核心服务部署在B7机房</p><h1 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h1><p>一般分布式跟踪系统, 主要有三个部分：数据收集，数据存储和数据展示。根据系统大小不同，每一部分的结构又有一定变化。譬如，对于大规模分布式系统，数据存储可分为实时数据和全量数据两部分，实时数据用于故障排查，全量数据用于系统优化；数据收集除了支持平台无关和开发语言无关系统的数据收集，还包括异步数据收集（需要跟踪队列中的消息，保证调用的连贯性），以及确保更小的侵入性；数据展示又涉及到数据挖掘和分享。虽然每一部分都可能变的很复杂，但基本原理都类似。<br><img src="http://mmbiz.qpic.cn/mmbiz/LaW7jDBKBg1jEGPib0DA4eZF7tBiclAzdsVRXstOJ1Fkhy40qqvGXzthGWP1enlosuiay0nhbiaJ8HQvBft0YetmDA/0?wx_fmt=png" alt="image"></p><p>图1：这个路径由用户的X请求发起，穿过一个简单的服务系统。用字母标识的节点代表分布式系统中的不同处理过程。</p><p>分布式服务的跟踪系统需要记录在一次特定的请求后系统中完成的所有工作的信息。举个例子，图1展现的是一个和5台服务器相关的一个服务，包括：前端（A），两个中间层（B和C），以及两个后端（D和E）。当一个用户（这个用例的发起人）发起一个请求时，首先到达前端，然后发送两个RPC到服务器B和C。B会马上做出反应，但是C需要和后端的D和E交互之后再返还给A，由A来响应最初的请求。对于这样一个请求，简单实用的分布式跟踪的实现，就是为服务器上每一次你发送和接收动作来收集跟踪标识符(message identifiers)和时间戳(timestamped events)。</p><h1 id="黑盒和标签方案"><a href="#黑盒和标签方案" class="headerlink" title="黑盒和标签方案"></a>黑盒和标签方案</h1><p>为了将所有记录条目与发起者惯量上并记录所有信息，现在有两种解决方案，黑盒和基于标签(annotation-based)的监控方案。<br>黑盒方案采用framework为基础，将依赖集成进去，对各接入业务线透明。基于标签的方案，依赖业务线明确标记一个trace id，从而连接每一条记录和发起者的请求。基于标签的方案主要缺点很明显，需要植入与业务无关代码。所以默认情况下，<strong>我们提供基于hjframework公共组件的方案</strong>，实现跟踪系统对业务无感知。同时如果需要显示使用这个标签功能的话，我们同样提供出来，由业务方自行决定是否使用标签。</p><h1 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h1><table><thead><tr><th>公司</th><th>选项</th><th>是否开源</th><th>优缺点</th></tr></thead><tbody><tr><td>淘宝</td><td>EagleEye</td><td>否</td><td>主要基于内部HSF实现，HSF没有开源，故鹰眼也没有开源</td></tr><tr><td>Twitter</td><td>Zipkin</td><td>是</td><td>基于Http实现，支持语言较多，比较适合我们公司业务</td></tr><tr><td>点评</td><td>CAT</td><td>是</td><td>自定义改造难度大，代码比较复杂，侵入代码，需要埋点</td></tr><tr><td>京东</td><td>Hydra</td><td>是</td><td>主要基于Dubbo实现，不适合公司Http请求为主的场景</td></tr></tbody></table><p>综上所述，最终我们觉得采用Zipkin的方式来实现，比较适合公司目前以Http请求为主的场景。虽然采用第三方开源产品，但是客户端依赖的SDK，仍需我们开发集成到HJFramewor中。针对Node和JS，Zipkin同样提供对应的前端SDK，我们集成好之后，就能正常使用。</p><h1 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h1><h2 id="整体架构图及说明"><a href="#整体架构图及说明" class="headerlink" title="整体架构图及说明"></a>整体架构图及说明</h2><p>基于Zipkin的基础上，我们对其架构进行了扩展，基于Google Dapper的概念，设计一套基于Http的分布式跟踪系统。其种涵盖了信息的收集，处理和展现。<br>整体架构如下图所示，主要由四个部分构成：收集器、数据传输、数据存储、查询及web界面</p><h3 id="收集器"><a href="#收集器" class="headerlink" title="收集器"></a>收集器</h3><p>业务方之间依赖我们提供的SDK，进行数据收集。其中SDK主要采用Spring Cloud中分布式跟踪模块是Spring Cloud Sleuth。该模块主要用于收集Spring boot系统中数据，发送至缓冲队列Kafka中。同时官方提供了针对Node、Python等一些常用的客户端SDK</p><h3 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h3><p>我们在SDK与后端服务之间加了一层Kafka，这样做既可以实现两边工程的解耦，又可以实现数据的延迟消费。我们不希望因为瞬时QPS过高而导致数据丢失，当然为此也付出了一些实效性上的代价。</p><h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><p>默认存储采用ElasticSearch 来保证数据，考虑到数据量的规模，先期只保存最近1个月的数据</p><h3 id="查询及Web界面"><a href="#查询及Web界面" class="headerlink" title="查询及Web界面"></a>查询及Web界面</h3><p>查询主要用来向其他服务提供数据查询的能力，而Web服务是官方默认提供的图形化界面，我们会重写这块页面，使之与沪江内部平台结合起来。</p><h3 id="SDK分析"><a href="#SDK分析" class="headerlink" title="SDK分析"></a>SDK分析</h3><p>调用链跟踪：把同一个TraceID和SpanID收集起来，按时间排序Timeline，把ParentID串起来就是调用栈。<br><img src="http://daixiaoyu.com/images/distributed-tracing/dt003.png" alt="image"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li>Google的大规模分布式系统的跟踪系统<a href="http://bigbully.github.io/Dapper-translation/" target="_blank" rel="noopener">Dapper</a></li><li>Twitter开源的<a href="http://zipkin.io/" target="_blank" rel="noopener">Zipkin</a></li><li>窝窝网介绍Tracing的一篇<a href="http://www.cnblogs.com/zhengyun_ustc/p/55solution2.html" target="_blank" rel="noopener">博客</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;公司业务由数以百计的分布式服务沟通，每一个请求路由过来后，会经过多个业务系统并留下足迹，并产生对各种缓存或者DB的访问，但是这些分散的数据对于问题排查，或者流程优化比较有限。对于一个跨进程的场景，汇总收集并分析海量日志就显得尤为重要。在这种架构下，跨进程的业务流会经过很多个微服务的处理和传递，我们难免会遇到这样的问题:&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="http://caolinhua.me/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="分布式跟踪" scheme="http://caolinhua.me/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B7%9F%E8%B8%AA/"/>
    
  </entry>
  
</feed>
